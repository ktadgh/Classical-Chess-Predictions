{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-16T17:29:42.105611879Z",
     "start_time": "2023-09-16T17:29:40.243678226Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "from itertools import islice\n",
    "import torch\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import hiddenlayer as hl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def to_list(str):\n",
    "    '''\n",
    "    :param str: string representing a list of centipawn losses\n",
    "    :return: list of integer centipawn losses\n",
    "    '''\n",
    "    string = str.replace('[','').replace(']','')\n",
    "    ls = string.split(',')\n",
    "    list = [float(i) for i in ls]\n",
    "\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def black_process(evals, clocks, start_time):\n",
    "    '''\n",
    "    :param eval: list of integer centipawn losses\n",
    "    :return: array of lists of [evaluation, centipawn loss]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    i = 0\n",
    "    old_eval = 36\n",
    "    old_clock = start_time\n",
    "    res = []\n",
    "\n",
    "    # iterating through centipawn losses\n",
    "    for eval in evals:\n",
    "\n",
    "        # subtracting the cpl for white's moves\n",
    "        if i % 2 ==1:\n",
    "            cpl = eval - old_eval\n",
    "            clock_time = old_clock - clocks[i]\n",
    "            res.append([cpl,clocks[i]])\n",
    "            old_eval = eval\n",
    "            old_clock = clocks[i]\n",
    "            i += 1\n",
    "\n",
    "        # adding the cpl for black's moves\n",
    "        else:\n",
    "            old_eval = eval\n",
    "            #old_clock -= clocks[i]\n",
    "            i+=1\n",
    "\n",
    "    return numpy.array(res)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def white_process(evals, clocks, start_time):\n",
    "    '''\n",
    "    :param eval: list of integer centipawn losses\n",
    "    :return: array of lists of [evaluation, centipawn loss]\n",
    "    '''\n",
    "\n",
    "    i = 0\n",
    "    old_eval = 36\n",
    "    old_clock = start_time\n",
    "    res = []\n",
    "\n",
    "    # iterating through centipawn losses\n",
    "    for eval in evals:\n",
    "\n",
    "        # subtracting the cpl for white's moves\n",
    "        if i % 2 ==0:\n",
    "            cpl = old_eval - eval\n",
    "            clock_time = old_clock - clocks[i]\n",
    "            res.append([cpl, clock_time])\n",
    "            old_eval = eval\n",
    "            old_clock = clocks[i]\n",
    "            i += 1\n",
    "\n",
    "        # adding the cpl for black's moves\n",
    "        else:\n",
    "            old_eval = eval\n",
    "            #old_clock -= clocks[i]\n",
    "            i+=1\n",
    "\n",
    "    return numpy.array(res)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('lichess_db_standard_rated_2023-08_1_1000000.csv', dtype  ={'Eval':'string'})"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# filtering out None or empty evaluations\n",
    "df = df[ df['Eval'].apply(lambda x: isinstance(x, str))]\n",
    "df = df[~df['Eval'].str.contains('None')]\n",
    "df = df[df['Eval']!='']\n",
    "df = df[df['Eval'] != '']\n",
    "df = df[df['Eval'] != '[]']"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.value_counts('TimeControl')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# picking a time control - I'm looking at 3 minute games\n",
    "df = df[df[\"TimeControl\"] == \"180+0\"]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filtering out * values\n",
    "df = df[df['WhiteELO'] != '*']\n",
    "df = df[df['BlackELO'] != '*']\n",
    "df[['WhiteELO', 'BlackELO']] = df[['WhiteELO', 'BlackELO']] .astype(int)\n",
    "\n",
    "# converting the evaluations and clock times to lists\n",
    "df['Eval'] = df['Eval'].apply( to_list)\n",
    "df['Clock'] = df['Clock'].apply(to_list)\n",
    "\n",
    "# processing the evaluations and clock times into feature sequences\n",
    "df['WhiteEval'] =df.apply(lambda x : white_process(x.Eval, x.Clock, 180), axis =1 )\n",
    "df['BlackEval'] = df.apply(lambda x : black_process(x.Eval, x.Clock, 180), axis =1 )"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Clock'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['WhiteEval'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# copying black's evaluations to the same column as white's, so we examine each game from both perspectives\n",
    "df_flipped = df.copy()\n",
    "df_flipped['WhiteEval'] = df_flipped['BlackEval']\n",
    "df_flipped['WhiteELO'] = df_flipped['BlackELO']\n",
    "df_flipped['White'] = df_flipped['Black']\n",
    "df = pd.concat([df, df_flipped])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Evaluted games: {len(df['Eval'])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regularizing Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "white_x = numpy.array(df['WhiteEval'])\n",
    "white_length = numpy.array(df['WhiteEval'].apply(len))\n",
    "\n",
    "black_x = numpy.array(df['WhiteEval'])\n",
    "black_length = numpy.array(df['WhiteEval'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# creating and fitting a power transformer for black and white\n",
    "wpt = StandardScaler()\n",
    "\n",
    "white_y = numpy.concatenate(white_x) # concatenating so that the data has shape (samples,features)\n",
    "\n",
    "wpt.fit(white_y)\n",
    "white_transformed = wpt.transform(white_y)\n",
    "\n",
    "bpt = PowerTransformer()\n",
    "black_y = numpy.concatenate(black_x)\n",
    "bpt.fit(black_y)\n",
    "black_transformed = bpt.transform(black_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "white_y"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "dump(wpt, 'w_eval_scaler.bin', compress=True)\n",
    "dump(bpt, 'b_eval_scaler.bin', compress=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['WhiteELO'].hist(bins = 200)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "white_elo_arr = numpy.array(df['WhiteELO'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#welopt = PowerTransformer(method = 'box-cox')\n",
    "welopt = StandardScaler()\n",
    "white_elo_arr = np.reshape(white_elo_arr, (len(white_elo_arr),1))\n",
    "welopt.fit(white_elo_arr)\n",
    "white_elo_transformed = welopt.transform(white_elo_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(white_elo_transformed, bins =20)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "white_transformed_array = [numpy.array(list(islice(iter(white_transformed), elem)))\n",
    "        for elem in white_length]\n",
    "\n",
    "black_transformed_array = [numpy.array(list(islice(iter(black_transformed), elem)))\n",
    "        for elem in black_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "white_transformed_array[0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into a training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# converting evaluations and length to tensors\n",
    "white_evals = [torch.tensor(i, dtype = torch.float32) for i in white_transformed_array]\n",
    "white_lengths = [len(tensor) for tensor in white_evals]\n",
    "\n",
    "black_evals = [torch.tensor(i, dtype = torch.float32) for i in black_transformed_array]\n",
    "black_lengths = [len(tensor) for tensor in black_evals]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def avg_cpl(white_processed):\n",
    "    '''\n",
    "    return the average centipawn loss from an evaluated game\n",
    "    :param white_processed: list of lists of the form [evaluation, centipawn loss]\n",
    "    :return: average centipawn loss (float)\n",
    "    '''\n",
    "    cpls = []\n",
    "    for i in white_processed:\n",
    "        cpls.append(i[1])\n",
    "    if len(cpls) == 0:\n",
    "        return float('NaN')\n",
    "    else:\n",
    "        return stats.mean(cpls)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['White_avg_cpl'] = df['WhiteEval'].copy().apply( avg_cpl )"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Converting White and Black's ELOs to tensors\n",
    "white_elo = [torch.tensor(i, dtype = torch.float32) for i in white_elo_transformed]\n",
    "\n",
    "\n",
    "\n",
    "black_elo = numpy.array(df['BlackELO'])\n",
    "black_elo = [torch.tensor(i, dtype = torch.float32) for i in black_elo]\n",
    "\n",
    "average_cpl = np.array(df['White_avg_cpl'])\n",
    "\n",
    "# splitting into train and test\n",
    "white_eval_train, white_eval_test, black_eval_train, black_eval_test, black_train, black_test, white_train, white_test, average_cpl_train, average_cpl_test = train_test_split(white_evals, black_evals, black_elo, white_elo, average_cpl, test_size=0.2,random_state=0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "white_train"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# zipping together the features and targets\n",
    "train_data_zip = list(zip(white_eval_train, white_train))\n",
    "test_data_zip = list(zip(white_eval_test, white_test))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "white_eval_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# black_elo = torch.stack(black_elo)\n",
    "# white_elo = torch.stack(white_elo)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "average_cpl_train = np.reshape(average_cpl_train, (len(average_cpl_train),1))\n",
    "average_cpl_test = np.reshape(average_cpl_test, (len(average_cpl_test),1))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "white_train_elo = np.array([x.item() for x in white_train])\n",
    "white_train_elo = np.reshape(white_train_elo, (len(white_train_elo),1 ))\n",
    "white_train_elo_transformed = welopt.inverse_transform(white_train_elo)\n",
    "\n",
    "white_test_elo = np.array([x.item() for x in white_test])\n",
    "white_test_elo = np.reshape(white_test_elo, (len(white_test_elo),1 ))\n",
    "white_test_elo_transformed = welopt.inverse_transform(white_test_elo)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make a simple linear regression model.\n",
    "regression = LinearRegression()\n",
    "regression.fit(average_cpl_train,white_train_elo_transformed)\n",
    "regression.score(average_cpl_test,white_test_elo)\n",
    "y_pred = regression.predict(average_cpl_test)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mse_lin = mean_squared_error(white_test_elo_transformed, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,15))\n",
    "plt.title('Linear regression model - Predicted ELO vs ELO', fontsize = 30)\n",
    "sns.regplot(x = white_test_elo_transformed, y = y_pred, line_kws = {'label':f'Mean Squared Error: {mse_lin:4f}'})\n",
    "plt.xlabel('ELO rating', fontsize = 25)\n",
    "plt.ylabel('Predicted ELO rating', fontsize = 25)\n",
    "plt.legend(prop={'size': 30})\n",
    "plt.savefig('images/NN_linreg_acc1.png')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, no_layers):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.no_layers = no_layers\n",
    "        torch.manual_seed(1)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, no_layers, batch_first = True, bias = True, dropout = 0.1)\n",
    "        torch.manual_seed(2)\n",
    "        self.fc = nn.Linear(hidden_size,1, bias = False)\n",
    "        self.final = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out, _ = self.lstm(x)\n",
    "        output ,lengths = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first = True)\n",
    "\n",
    "\n",
    "        out = [output[e, i-1,:].unsqueeze(0)for e, i in enumerate(lengths)]\n",
    "        out = torch.cat(out, dim = 0)\n",
    "\n",
    "\n",
    "        out = self.fc(out)\n",
    "        out = self.final(out)\n",
    "        out = out[:,0]\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    '''\n",
    "    Yields a batch from a list of Items\n",
    "    Args:\n",
    "    test : Set True when using with test data loader. Defaults to False\n",
    "    percentile : Trim sequences by this percentile\n",
    "    '''\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        white_data = [item[0] for item in batch]\n",
    "        target = [item[1] for item in batch]\n",
    "        white_lens = [i.shape[0] for i in white_data]\n",
    "\n",
    "        white_data = torch.nn.utils.rnn.pad_sequence(white_data, batch_first=True,padding_value = 0)\n",
    "        white_evals_packed = torch.nn.utils.rnn.pack_padded_sequence(white_data,batch_first = True, lengths=white_lens,enforce_sorted=False)\n",
    "\n",
    "        target = torch.tensor(target,dtype=torch.float32)\n",
    "        return [white_evals_packed, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameters for the neural net\n",
    "input_size = 2\n",
    "hidden_size = 50\n",
    "no_layers = 6\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLSTM(input_size, hidden_size, no_layers)\n",
    "collate = MyCollator()\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/h45l4-2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_data_zip, batch_size=batch_size, shuffle=True ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "avg_losses = []\n",
    "epochs = []\n",
    "avg_loss = 0.1\n",
    "\n",
    "for epoch in range(1000):\n",
    "    data_loader = torch.utils.data.DataLoader(train_data_zip, batch_size=batch_size, shuffle=True,collate_fn=collate)\n",
    "    # if (epoch+1) % 3 == 0:\n",
    "    #     learning_rate /= 2\n",
    "    #     optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    i = 0\n",
    "    for white_evals, elo in data_loader:\n",
    "        white_evals = white_evals.to(device)\n",
    "        elo = elo.to(device)\n",
    "        outputs = model(white_evals)\n",
    "        loss = criterion(outputs,elo)\n",
    "\n",
    "        # optimizing\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        i+=1\n",
    "\n",
    "    change = stats.mean(losses)/avg_loss\n",
    "    avg_loss = stats.mean(losses)\n",
    "\n",
    "    # adding histograms to the summary writer\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(name, np.array(param.detach().tolist()), epoch)\n",
    "\n",
    "    # adding loss\n",
    "    writer.add_scalar('Average loss',avg_loss, epoch)\n",
    "    avg_losses.append(avg_loss)\n",
    "    epochs.append(epoch)\n",
    "    print(f'Epoch {epoch+1} step {i+1} - Learning Rate : {learning_rate}- Avg Loss: {avg_loss:3f} - Change in loss: {change}')\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(epochs, avg_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model =model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = torch.utils.data.DataLoader(test_data_zip, batch_size=1, shuffle=False ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "outputs = []\n",
    "elos = []\n",
    "for evals, elo in test_data_loader:\n",
    "    #print(\"evals\",evals.shape)\n",
    "    evals = evals.to(device)\n",
    "    elo = elo.to(device)\n",
    "    output = model(evals)\n",
    "    outputs.append(output.item())\n",
    "    elos.append(elo.item())\n",
    "    loss = criterion(output,elo)\n",
    "    #print(f'Model prediction : {output} \\n ELO : {elo} \\n MSE : {loss}')\n",
    "    losses.append(loss.item())\n",
    "print(f'Average loss : {stats.mean(losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preparing data to be inverse transformed\n",
    "elos = np.array(elos)\n",
    "elos = np.reshape(elos, (len(elos),1))\n",
    "\n",
    "outputs = np.array(outputs)\n",
    "outputs = np.reshape(outputs, (len(outputs),1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# getting elos from the normalized values\n",
    "elos = welopt.inverse_transform(elos)\n",
    "outputs = welopt.inverse_transform(outputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.shape(elos)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mse_model = mean_squared_error(elos,outputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,15))\n",
    "plt.title('Neural Network - Predicted ELO vs ELO', fontsize = 30)\n",
    "sns.regplot(x = elos, y = outputs, color ='green', line_kws = {'label':f'Mean Squared Error: {mse_model:4f}'})\n",
    "plt.xlabel('ELO rating ', fontsize = 25)\n",
    "plt.ylabel('Predicted ELO rating', fontsize = 25)\n",
    "plt.legend(prop={'size': 30})\n",
    "plt.savefig('images/NN_model_acc1.png')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'basic_model.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('basic_model.pt'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(elos,outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the neural net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plotting the neural net architecture\n",
    "#dot = make_dot(output, params=model.params, show_attrs=False, show_saved=False)\n",
    "#dot.render(\"rnn_torchviz3\", format=\"pdf\", engine= 'neato')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
