{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from torchviz import make_dot\n",
    "from itertools import islice\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(str):\n",
    "    '''\n",
    "    :param str: string representing a list of centipawn losses\n",
    "    :return: list of integer centipawn losses\n",
    "    '''\n",
    "    string = str.replace('[','').replace(']','')\n",
    "    ls = string.split(',')\n",
    "    list = [int(i) for i in ls]\n",
    "\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(eval):\n",
    "    '''\n",
    "    :param eval: list of integer centipawn losses\n",
    "    :return: array of lists of [evaluation, centipawn loss]\n",
    "    '''\n",
    "\n",
    "    # starting evaluation of 30 centipawns\n",
    "    sum = 30\n",
    "\n",
    "    i = 0\n",
    "    res = []\n",
    "\n",
    "    # iterating through centipawn losses\n",
    "    for cpl in eval:\n",
    "\n",
    "        # subtracting the cpl for white's moves\n",
    "        if i % 2 ==0:\n",
    "            res.append([sum,cpl])\n",
    "            sum -= cpl\n",
    "            i += 1\n",
    "\n",
    "        # adding the cpl for black's moves\n",
    "        else:\n",
    "            sum+=cpl\n",
    "            i+=1\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  games: 4210\n",
      "Evaluted games: 434\n"
     ]
    }
   ],
   "source": [
    "# reading *some* of the data\n",
    "dfs = []\n",
    "\n",
    "players = ['andreikin, dmitry', 'anand, viswanathan', 'wang, hao', 'grischuk, alexander', 'karjakin, sergey','duda, jan-krzysztof', 'radjabov, teimour', 'dominguez perez, leinier','nakamura, hikaru', 'vachier-lagrave, maxime','aronian, levon','mamedyarov, shakhriyar', 'so, wesley','ding, liren', 'rapport, richard', 'nepomniachtchi, ian', 'giri, anish', 'firouzja, alireza', 'caruana, fabiano','carlsen, magnus','zelcic, robert','khotenashvili, bela', 'bischoff, klaus', 'hoffmann, asa','kaufman, lawrence','bellaiche, elise']\n",
    "\n",
    "# reading the csvs\n",
    "for player in players:\n",
    "    df = pd.read_csv('blitz/'+player +'.csv')\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "\n",
    "print(f\"Total  games: {len(df)}\")\n",
    "\n",
    "# Filtering out * values\n",
    "df = df[df['WhiteELO'] != '*']\n",
    "df = df[df['BlackELO'] != '*']\n",
    "df[['WhiteELO', 'BlackELO']] = df[['WhiteELO', 'BlackELO']] .astype(int)\n",
    "\n",
    "df = df[df['Eval'] != '']\n",
    "df = df[ df['Eval'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "\n",
    "# converting the evaluation to a list\n",
    "df['Eval'] = df['Eval'].apply( to_list)\n",
    "df['Eval'] = df['Eval'].apply( process )\n",
    "\n",
    "print(f\"Evaluted games: {len(df['Eval'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df['Eval'])\n",
    "length = np.array(df['Eval'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and fitting a power transformer\n",
    "pt = PowerTransformer()\n",
    "y = np.concatenate(x)\n",
    "pt.fit(y)\n",
    "transformed = pt.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a function now to (effieciently) change these to lists of length list\n",
    "transformed_array = [np.array(list(islice(iter(transformed), elem)))\n",
    "        for elem in length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique evaluated games: 422\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique evaluated games: {df['Game'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting evaluations and length to tensors\n",
    "evals = [torch.tensor(i, dtype = torch.float32) for i in transformed_array]\n",
    "lengths = [len(tensor) for tensor in evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding my sequences - not sure why batch first works, but it does\n",
    "#inputs = torch.nn.utils.rnn.pad_sequence(evals, batch_first=True, padding_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_array = np.array(inputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_list =inputs.tolist()\n",
    "\n",
    "# normalizing... a bit hacky\n",
    "#inputs_array = (np.array(inputs_list) - np.array(inputs_list).mean())/ np.linalg.norm(np.array(inputs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    '''\n",
    "    :param array:\n",
    "    :return:\n",
    "    '''\n",
    "    return (array - array.mean())/array.std()\n",
    "\n",
    "def denormalize(array, value):\n",
    "    '''\n",
    "    :param array:\n",
    "    :param value:\n",
    "    :return:\n",
    "    '''\n",
    "    return value*array.std() + array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['WhiteELO'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting White and Black's ELOs to tensors\n",
    "white_elo_arr = np.array(df['WhiteELO'])\n",
    "\n",
    "white_elo = normalize(white_elo_arr)\n",
    "\n",
    "#print(white_elo)\n",
    "white_elo = [torch.tensor(i, dtype = torch.float32) for i in white_elo]\n",
    "\n",
    "\n",
    "\n",
    "black_elo = np.array(df['BlackELO'])\n",
    "black_elo = [torch.tensor(i, dtype = torch.float32) for i in black_elo]\n",
    "\n",
    "\n",
    "# splitting into train and test\n",
    "lengths_train, lengths_test,eval_train, eval_test, black_train, black_test, white_train, white_test  = train_test_split(lengths, evals, black_elo, white_elo, test_size=0.2,random_state=0, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping the elo together with the evaluations\n",
    "train_data_zip = list(zip(eval_train, white_train))\n",
    "test_data_zip = list(zip(eval_test, white_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_elo = torch.stack(black_elo)\n",
    "white_elo = torch.stack(white_elo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, no_layers):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.no_layers = no_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, no_layers, batch_first = True, bias = True)\n",
    "        self.fc = nn.Linear(hidden_size,1, bias = False)\n",
    "        self.final = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        t, l = torch.nn.utils.rnn.pad_packed_sequence(x)\n",
    "\n",
    "        # initial hidden state\n",
    "        #h0 = torch.rand(self.no_layers,batch_size,self.hidden_size)\n",
    "\n",
    "        out, _ = self.rnn(x)\n",
    "\n",
    "\n",
    "        # shape batches, seq_length, hidden_size\n",
    "        output ,lengths = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first = True)\n",
    "\n",
    "        out = [output[e, i-1,:].unsqueeze(0) for e, i in enumerate(lengths)]\n",
    "\n",
    "        out = torch.cat(out, dim = 0)\n",
    "        #print(out.shape)\n",
    "        #print(\"Linear weights\", self.fc.weight)\n",
    "\n",
    "\n",
    "        out = self.fc(out)\n",
    "        out = self.final(out)\n",
    "        #print(out.shape)\n",
    "\n",
    "        return out[:,0]\n",
    "\n",
    "\n",
    "    #def init_hidden(self):\n",
    "    #    return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))\n",
    "\n",
    "# need to figure out exactly how the dimensions changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    '''\n",
    "    Yields a batch from a list of Items\n",
    "    Args:\n",
    "    test : Set True when using with test data loader. Defaults to False\n",
    "    percentile : Trim sequences by this percentile\n",
    "    '''\n",
    "\n",
    "    # remove that eventually. I'm going to need to make my dataset a tuple with evals and elo\n",
    "    #def __init__(self):\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        data = [item[0] for item in batch]\n",
    "        target = [item[1] for item in batch]\n",
    "        lens = [i.shape[0] for i in data]\n",
    "\n",
    "        #print(lens)\n",
    "        data = torch.nn.utils.rnn.pad_sequence(data, batch_first=True,padding_value = 0)\n",
    "        #data = data.unsqueeze(2)\n",
    "        #print(\"PADDED\",data)\n",
    "        evals_packed = torch.nn.utils.rnn.pack_padded_sequence(data,batch_first = True, lengths=lens,enforce_sorted=False)\n",
    "\n",
    "        target = torch.tensor(target,dtype=torch.float32)\n",
    "        return [evals_packed,target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 20\n",
    "no_layers = 3\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (defining my model)\n",
    "model = MyRNN(input_size, hidden_size, no_layers)\n",
    "collate = MyCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print('name: ', name)\n",
    "#     print(type(param))\n",
    "#     print('param.shape: ', param.shape)\n",
    "#     print('param.requires_grad: ', param.requires_grad)\n",
    "#     print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_train = [torch.tensor(i, dtype = torch.float32) for i in eval_train]\n",
    "#white_train = [torch.tensor(i, dtype = torch.float32) for i in white_train]\n",
    "\n",
    "#eval_train = torch.stack(eval_train)\n",
    "#white_train = torch.stack(white_train)\n",
    "\n",
    "#train_data = list(zip(evals_packed, white_train))\n",
    "\n",
    "\n",
    "#eval_test = [torch.tensor(i, dtype=torch.float32) for i in eval_test]\n",
    "#white_test = [torch.tensor(i, dtype=torch.float32) for i in white_test]\n",
    "\n",
    "#eval_test = torch.stack(eval_test)\n",
    "#white_test = torch.stack(white_test)\n",
    "\n",
    "\n",
    "# not sure why I'm seeing a warning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MyRNN(\n",
      "  (rnn): RNN(2, 20, num_layers=3, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=1, bias=False)\n",
      "  (final): Tanh()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_data_zip, batch_size=batch_size, shuffle=True ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK I've figured out the issue, I also need the sequence length for the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 step 71 - Learning Rate : 0.2- Avg Loss: 0.987626 - Change in loss: 0.9876262684485742\n",
      "Epoch 2 step 71 - Learning Rate : 0.2- Avg Loss: 0.968867 - Change in loss: 0.9810052528514919\n",
      "Epoch 3 step 71 - Learning Rate : 0.2- Avg Loss: 0.978322 - Change in loss: 1.0097590331161888\n",
      "Epoch 4 step 71 - Learning Rate : 0.2- Avg Loss: 0.966762 - Change in loss: 0.9881843884216049\n",
      "Epoch 5 step 71 - Learning Rate : 0.2- Avg Loss: 0.966832 - Change in loss: 1.0000721153307741\n",
      "Epoch 6 step 71 - Learning Rate : 0.2- Avg Loss: 0.976002 - Change in loss: 1.0094842948229121\n",
      "Epoch 7 step 71 - Learning Rate : 0.2- Avg Loss: 0.965527 - Change in loss: 0.9892681615767512\n",
      "Epoch 8 step 71 - Learning Rate : 0.2- Avg Loss: 0.969246 - Change in loss: 1.0038517813056147\n",
      "Epoch 9 step 71 - Learning Rate : 0.2- Avg Loss: 0.966527 - Change in loss: 0.9971938101814241\n",
      "Epoch 10 step 71 - Learning Rate : 0.1- Avg Loss: 0.966592 - Change in loss: 1.0000675687597242\n",
      "Epoch 11 step 71 - Learning Rate : 0.1- Avg Loss: 1.018369 - Change in loss: 1.0535665137473182\n",
      "Epoch 12 step 71 - Learning Rate : 0.1- Avg Loss: 0.970916 - Change in loss: 0.9534031142284212\n",
      "Epoch 13 step 71 - Learning Rate : 0.1- Avg Loss: 0.965720 - Change in loss: 0.994648783586617\n",
      "Epoch 14 step 71 - Learning Rate : 0.1- Avg Loss: 0.965899 - Change in loss: 1.0001846370011729\n",
      "Epoch 15 step 71 - Learning Rate : 0.1- Avg Loss: 0.966004 - Change in loss: 1.0001085417246052\n",
      "Epoch 16 step 71 - Learning Rate : 0.1- Avg Loss: 0.965364 - Change in loss: 0.999338231115423\n",
      "Epoch 17 step 71 - Learning Rate : 0.1- Avg Loss: 0.965440 - Change in loss: 1.0000786527412806\n",
      "Epoch 18 step 71 - Learning Rate : 0.1- Avg Loss: 0.963085 - Change in loss: 0.9975604252280733\n",
      "Epoch 19 step 71 - Learning Rate : 0.1- Avg Loss: 0.964663 - Change in loss: 1.001638482063669\n",
      "Epoch 20 step 71 - Learning Rate : 0.05- Avg Loss: 0.965908 - Change in loss: 1.0012903273984048\n",
      "Epoch 21 step 71 - Learning Rate : 0.05- Avg Loss: 0.963191 - Change in loss: 0.9971875451612029\n",
      "Epoch 22 step 71 - Learning Rate : 0.05- Avg Loss: 0.984275 - Change in loss: 1.0218896477139088\n",
      "Epoch 23 step 71 - Learning Rate : 0.05- Avg Loss: 0.966633 - Change in loss: 0.982076542978352\n",
      "Epoch 24 step 71 - Learning Rate : 0.05- Avg Loss: 0.965128 - Change in loss: 0.998442655871557\n",
      "Epoch 25 step 71 - Learning Rate : 0.05- Avg Loss: 0.963052 - Change in loss: 0.997849331288628\n",
      "Epoch 26 step 71 - Learning Rate : 0.05- Avg Loss: 0.962206 - Change in loss: 0.9991212537324315\n",
      "Epoch 27 step 71 - Learning Rate : 0.05- Avg Loss: 0.961227 - Change in loss: 0.9989829100325345\n",
      "Epoch 28 step 71 - Learning Rate : 0.05- Avg Loss: 0.962944 - Change in loss: 1.0017863135296483\n",
      "Epoch 29 step 71 - Learning Rate : 0.05- Avg Loss: 0.959893 - Change in loss: 0.996831211620489\n",
      "Epoch 30 step 71 - Learning Rate : 0.025- Avg Loss: 0.959885 - Change in loss: 0.9999914787801909\n",
      "Epoch 31 step 71 - Learning Rate : 0.025- Avg Loss: 0.969802 - Change in loss: 1.0103316083288894\n",
      "Epoch 32 step 71 - Learning Rate : 0.025- Avg Loss: 0.957500 - Change in loss: 0.9873152823299108\n",
      "Epoch 33 step 71 - Learning Rate : 0.025- Avg Loss: 0.957751 - Change in loss: 1.0002616520458245\n",
      "Epoch 34 step 71 - Learning Rate : 0.025- Avg Loss: 0.959805 - Change in loss: 1.0021448417754373\n",
      "Epoch 35 step 71 - Learning Rate : 0.025- Avg Loss: 0.957073 - Change in loss: 0.9971535609025908\n",
      "Epoch 36 step 71 - Learning Rate : 0.025- Avg Loss: 0.957219 - Change in loss: 1.0001525665294302\n",
      "Epoch 37 step 71 - Learning Rate : 0.025- Avg Loss: 0.958555 - Change in loss: 1.0013952463840423\n",
      "Epoch 38 step 71 - Learning Rate : 0.025- Avg Loss: 0.960727 - Change in loss: 1.0022659788849217\n",
      "Epoch 39 step 71 - Learning Rate : 0.025- Avg Loss: 0.955839 - Change in loss: 0.9949124781147196\n",
      "Epoch 40 step 71 - Learning Rate : 0.0125- Avg Loss: 0.953868 - Change in loss: 0.9979379917473071\n",
      "Epoch 41 step 71 - Learning Rate : 0.0125- Avg Loss: 0.954699 - Change in loss: 1.0008714617341405\n",
      "Epoch 42 step 71 - Learning Rate : 0.0125- Avg Loss: 0.954151 - Change in loss: 0.9994253932951508\n",
      "Epoch 43 step 71 - Learning Rate : 0.0125- Avg Loss: 0.960698 - Change in loss: 1.006861363514396\n",
      "Epoch 44 step 71 - Learning Rate : 0.0125- Avg Loss: 0.967070 - Change in loss: 1.006633222393379\n",
      "Epoch 45 step 71 - Learning Rate : 0.0125- Avg Loss: 0.952836 - Change in loss: 0.9852814196311424\n",
      "Epoch 46 step 71 - Learning Rate : 0.0125- Avg Loss: 0.951330 - Change in loss: 0.9984187629461931\n",
      "Epoch 47 step 71 - Learning Rate : 0.0125- Avg Loss: 0.956742 - Change in loss: 1.0056894892243975\n",
      "Epoch 48 step 71 - Learning Rate : 0.0125- Avg Loss: 0.951308 - Change in loss: 0.9943202361504057\n",
      "Epoch 49 step 71 - Learning Rate : 0.0125- Avg Loss: 0.950832 - Change in loss: 0.9994996381896646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []\n",
    "epochs = []\n",
    "avg_loss = 1\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    if (epoch+1) % 10 ==0:\n",
    "        learning_rate /= 2\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    i = 0\n",
    "    losses = []\n",
    "    for evals, elo in data_loader:\n",
    "        evals = evals.to(device)\n",
    "\n",
    "        elo = elo.to(device)\n",
    "        i +=1\n",
    "        outputs = model(evals)\n",
    "        #print(outputs)\n",
    "        #print(outputs.shape, elo.shape)\n",
    "        loss = criterion(outputs,elo)\n",
    "\n",
    "        # optimizing\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    change = stats.mean(losses)/avg_loss\n",
    "    avg_loss = stats.mean(losses)\n",
    "    avg_losses.append(avg_loss)\n",
    "    epochs.append(epoch)\n",
    "    print(f'Epoch {epoch+1} step {i+1} - Learning Rate : {learning_rate}- Avg Loss: {avg_loss:3f} - Change in loss: {change}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why are 4/5 always zero???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x2c01d84d720>"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(epochs, avg_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "MyRNN(\n  (rnn): RNN(2, 20, num_layers=3, batch_first=True)\n  (fc): Linear(in_features=20, out_features=1, bias=False)\n  (final): Tanh()\n)"
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = torch.utils.data.DataLoader(test_data_zip, batch_size=1, shuffle=False ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss : 1.1342573041943853\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "outputs = []\n",
    "elos = []\n",
    "for evals, elo in test_data_loader:\n",
    "    #print(\"evals\",evals.shape)\n",
    "    evals = evals.to(device)\n",
    "    elo = elo.to(device)\n",
    "    output = model(evals)\n",
    "    outputs.append(output.item())\n",
    "    elos.append(elo.item())\n",
    "    loss = criterion(output,elo)\n",
    "    #print(f'Model prediction : {output} \\n ELO : {elo} \\n MSE : {loss}')\n",
    "    losses.append(loss.item())\n",
    "print(f'Average loss : {stats.mean(losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.0804], grad_fn=<SelectBackward0>)"
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x2c01d8265f0>"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(elos,outputs, alpha = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the neural net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "# note - to use any of these, I'm not sure that I can use the packed sequence. I would have to change the way the NN works, a little bit\n",
    "tb = SummaryWriter()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2056439369916916\n",
      "-0.2929120361804962\n"
     ]
    }
   ],
   "source": [
    "print(max(outputs))\n",
    "print(min(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MyRNN.forward() takes 2 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [174]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m traced_script_module \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevals\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\jit\\_trace.py:759\u001B[0m, in \u001B[0;36mtrace\u001B[1;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001B[0m\n\u001B[0;32m    756\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func\n\u001B[0;32m    758\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[1;32m--> 759\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrace_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    761\u001B[0m \u001B[43m        \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforward\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    762\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    763\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_trace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    764\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwrap_check_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheck_inputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    765\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_tolerance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    766\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    767\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    768\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_module_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    769\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    771\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    772\u001B[0m     \u001B[38;5;28mhasattr\u001B[39m(func, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__self__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    773\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m, torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule)\n\u001B[0;32m    774\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforward\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    775\u001B[0m ):\n\u001B[0;32m    776\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trace_module(\n\u001B[0;32m    777\u001B[0m         func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m,\n\u001B[0;32m    778\u001B[0m         {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforward\u001B[39m\u001B[38;5;124m\"\u001B[39m: example_inputs},\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    785\u001B[0m         _module_class,\n\u001B[0;32m    786\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\jit\\_trace.py:976\u001B[0m, in \u001B[0;36mtrace_module\u001B[1;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001B[0m\n\u001B[0;32m    972\u001B[0m     argument_names \u001B[38;5;241m=\u001B[39m get_callable_argument_names(func)\n\u001B[0;32m    974\u001B[0m example_inputs \u001B[38;5;241m=\u001B[39m make_tuple(example_inputs)\n\u001B[1;32m--> 976\u001B[0m \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_c\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_method_from_trace\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    978\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    979\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexample_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    980\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvar_lookup_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    981\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    982\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[43m    \u001B[49m\u001B[43margument_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    984\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    985\u001B[0m check_trace_method \u001B[38;5;241m=\u001B[39m module\u001B[38;5;241m.\u001B[39m_c\u001B[38;5;241m.\u001B[39m_get_method(method_name)\n\u001B[0;32m    987\u001B[0m \u001B[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1182\u001B[0m, in \u001B[0;36mModule._slow_forward\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1180\u001B[0m         recording_scopes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1182\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1183\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1184\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m recording_scopes:\n",
      "\u001B[1;31mTypeError\u001B[0m: MyRNN.forward() takes 2 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "traced_script_module = torch.jit.trace(model, evals)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# note - doesn't support packed stuff\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.add_graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, no_layers):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.no_layers = no_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, no_layers, batch_first = True, bias = False)\n",
    "        self.fc = nn.Linear(hidden_size,1, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # initial hidden state\n",
    "        h0 = torch.rand(self.no_layers,x.size(0),self.hidden_size)\n",
    "\n",
    "        out, _ = self.rnn(x,h0)\n",
    "        #print(out) #return out\n",
    "        out = out[:,-1,:]\n",
    "        #print(out)\n",
    "        out = self.fc(out)\n",
    "        #print(out)\n",
    "        m = nn.Sigmoid()\n",
    "        out = m(out)\n",
    "        return out\n",
    "        # print(\"out: \",out)\n",
    "        # print('RNN WEIGHTS: ',self.rnn.weight_ih_l0  )\n",
    "        # print(self.fc.weight)\n",
    "        #\n",
    "        # #print(\"Count these...\",out)\n",
    "        # m = nn.Sigmoid()\n",
    "        # out = m(out)\n",
    "        # if x.size(0) == 1:\n",
    "        #     return out[0]\n",
    "        # else:\n",
    "        #     return torch.squeeze(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyRNN(input_size, hidden_size, no_layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
