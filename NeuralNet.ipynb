{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from torchviz import make_dot\n",
    "from itertools import islice\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import hiddenlayer as hl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(str):\n",
    "    '''\n",
    "    :param str: string representing a list of centipawn losses\n",
    "    :return: list of integer centipawn losses\n",
    "    '''\n",
    "    string = str.replace('[','').replace(']','')\n",
    "    ls = string.split(',')\n",
    "    list = [int(i) for i in ls]\n",
    "\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(eval):\n",
    "    '''\n",
    "    :param eval: list of integer centipawn losses\n",
    "    :return: array of lists of [evaluation, centipawn loss]\n",
    "    '''\n",
    "\n",
    "    # starting evaluation of 30 centipawns\n",
    "    sum = 30\n",
    "\n",
    "    i = 0\n",
    "    res = []\n",
    "\n",
    "    # iterating through centipawn losses\n",
    "    for cpl in eval:\n",
    "\n",
    "        # subtracting the cpl for white's moves\n",
    "        if i % 2 ==0:\n",
    "            res.append([sum,cpl])\n",
    "            sum -= cpl\n",
    "            i += 1\n",
    "\n",
    "        # adding the cpl for black's moves\n",
    "        else:\n",
    "            sum+=cpl\n",
    "            i+=1\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  games: 4210\n",
      "Evaluted games: 434\n"
     ]
    }
   ],
   "source": [
    "# reading *some* of the data\n",
    "dfs = []\n",
    "\n",
    "players = ['andreikin, dmitry', 'anand, viswanathan', 'wang, hao', 'grischuk, alexander', 'karjakin, sergey','duda, jan-krzysztof', 'radjabov, teimour', 'dominguez perez, leinier','nakamura, hikaru', 'vachier-lagrave, maxime','aronian, levon','mamedyarov, shakhriyar', 'so, wesley','ding, liren', 'rapport, richard', 'nepomniachtchi, ian', 'giri, anish', 'firouzja, alireza', 'caruana, fabiano','carlsen, magnus','zelcic, robert','khotenashvili, bela', 'bischoff, klaus', 'hoffmann, asa','kaufman, lawrence','bellaiche, elise']\n",
    "\n",
    "# reading the csvs\n",
    "for player in players:\n",
    "    df = pd.read_csv('blitz/'+player +'.csv')\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "\n",
    "print(f\"Total  games: {len(df)}\")\n",
    "\n",
    "# Filtering out * values\n",
    "df = df[df['WhiteELO'] != '*']\n",
    "df = df[df['BlackELO'] != '*']\n",
    "df[['WhiteELO', 'BlackELO']] = df[['WhiteELO', 'BlackELO']] .astype(int)\n",
    "\n",
    "df = df[df['Eval'] != '']\n",
    "df = df[ df['Eval'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "\n",
    "# converting the evaluation to a list\n",
    "df['Eval'] = df['Eval'].apply( to_list)\n",
    "df['Eval'] = df['Eval'].apply( process )\n",
    "\n",
    "print(f\"Evaluted games: {len(df['Eval'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df['Eval'])\n",
    "length = np.array(df['Eval'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and fitting a power transformer\n",
    "pt = PowerTransformer()\n",
    "y = np.concatenate(x)\n",
    "pt.fit(y)\n",
    "transformed = pt.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a function now to (effieciently) change these to lists of length list\n",
    "transformed_array = [np.array(list(islice(iter(transformed), elem)))\n",
    "        for elem in length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique evaluated games: 422\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique evaluated games: {df['Game'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting evaluations and length to tensors\n",
    "evals = [torch.tensor(i, dtype = torch.float32) for i in transformed_array]\n",
    "lengths = [len(tensor) for tensor in evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding my sequences - not sure why batch first works, but it does\n",
    "#inputs = torch.nn.utils.rnn.pad_sequence(evals, batch_first=True, padding_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_array = np.array(inputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_list =inputs.tolist()\n",
    "\n",
    "# normalizing... a bit hacky\n",
    "#inputs_array = (np.array(inputs_list) - np.array(inputs_list).mean())/ np.linalg.norm(np.array(inputs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    '''\n",
    "    :param array:\n",
    "    :return:\n",
    "    '''\n",
    "    return (array - array.mean())/array.std()\n",
    "\n",
    "def denormalize(array, value):\n",
    "    '''\n",
    "    :param array:\n",
    "    :param value:\n",
    "    :return:\n",
    "    '''\n",
    "    return value*array.std() + array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['WhiteELO'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting White and Black's ELOs to tensors\n",
    "white_elo_arr = np.array(df['WhiteELO'])\n",
    "\n",
    "white_elo = normalize(white_elo_arr)\n",
    "\n",
    "#print(white_elo)\n",
    "white_elo = [torch.tensor(i, dtype = torch.float32) for i in white_elo]\n",
    "\n",
    "\n",
    "\n",
    "black_elo = np.array(df['BlackELO'])\n",
    "black_elo = [torch.tensor(i, dtype = torch.float32) for i in black_elo]\n",
    "\n",
    "\n",
    "# splitting into train and test\n",
    "lengths_train, lengths_test,eval_train, eval_test, black_train, black_test, white_train, white_test  = train_test_split(lengths, evals, black_elo, white_elo, test_size=0.2,random_state=0, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping the elo together with the evaluations\n",
    "train_data_zip = list(zip(eval_train, white_train))\n",
    "test_data_zip = list(zip(eval_test, white_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_elo = torch.stack(black_elo)\n",
    "white_elo = torch.stack(white_elo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, no_layers):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.no_layers = no_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, no_layers, batch_first = True, bias = True)\n",
    "        self.fc = nn.Linear(hidden_size,1, bias = False)\n",
    "        self.final = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        t, l = torch.nn.utils.rnn.pad_packed_sequence(x)\n",
    "\n",
    "        # initial hidden state\n",
    "        #h0 = torch.rand(self.no_layers,batch_size,self.hidden_size)\n",
    "\n",
    "        out, _ = self.rnn(x)\n",
    "\n",
    "\n",
    "        # shape batches, seq_length, hidden_size\n",
    "        output ,lengths = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first = True)\n",
    "\n",
    "        out = [output[e, i-1,:].unsqueeze(0) for e, i in enumerate(lengths)]\n",
    "\n",
    "        out = torch.cat(out, dim = 0)\n",
    "        #print(out.shape)\n",
    "        #print(\"Linear weights\", self.fc.weight)\n",
    "\n",
    "\n",
    "        out = self.fc(out)\n",
    "        out = self.final(out)\n",
    "        #print(out.shape)\n",
    "\n",
    "        return out[:,0]\n",
    "\n",
    "\n",
    "    #def init_hidden(self):\n",
    "    #    return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))\n",
    "\n",
    "# need to figure out exactly how the dimensions changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    '''\n",
    "    Yields a batch from a list of Items\n",
    "    Args:\n",
    "    test : Set True when using with test data loader. Defaults to False\n",
    "    percentile : Trim sequences by this percentile\n",
    "    '''\n",
    "\n",
    "    # remove that eventually. I'm going to need to make my dataset a tuple with evals and elo\n",
    "    #def __init__(self):\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        data = [item[0] for item in batch]\n",
    "        target = [item[1] for item in batch]\n",
    "        lens = [i.shape[0] for i in data]\n",
    "\n",
    "        #print(lens)\n",
    "        data = torch.nn.utils.rnn.pad_sequence(data, batch_first=True,padding_value = 0)\n",
    "        #data = data.unsqueeze(2)\n",
    "        #print(\"PADDED\",data)\n",
    "        evals_packed = torch.nn.utils.rnn.pack_padded_sequence(data,batch_first = True, lengths=lens,enforce_sorted=False)\n",
    "\n",
    "        target = torch.tensor(target,dtype=torch.float32)\n",
    "        return [evals_packed,target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 20\n",
    "no_layers = 3\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (defining my model)\n",
    "model = MyRNN(input_size, hidden_size, no_layers)\n",
    "collate = MyCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print('name: ', name)\n",
    "#     print(type(param))\n",
    "#     print('param.shape: ', param.shape)\n",
    "#     print('param.requires_grad: ', param.requires_grad)\n",
    "#     print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_train = [torch.tensor(i, dtype = torch.float32) for i in eval_train]\n",
    "#white_train = [torch.tensor(i, dtype = torch.float32) for i in white_train]\n",
    "\n",
    "#eval_train = torch.stack(eval_train)\n",
    "#white_train = torch.stack(white_train)\n",
    "\n",
    "#train_data = list(zip(evals_packed, white_train))\n",
    "\n",
    "\n",
    "#eval_test = [torch.tensor(i, dtype=torch.float32) for i in eval_test]\n",
    "#white_test = [torch.tensor(i, dtype=torch.float32) for i in white_test]\n",
    "\n",
    "#eval_test = torch.stack(eval_test)\n",
    "#white_test = torch.stack(white_test)\n",
    "\n",
    "\n",
    "# not sure why I'm seeing a warning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MyRNN(\n",
      "  (rnn): RNN(2, 20, num_layers=3, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=1, bias=False)\n",
      "  (final): Tanh()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_data_zip, batch_size=batch_size, shuffle=True ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK I've figured out the issue, I also need the sequence length for the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 step 71 - Learning Rate : 0.2- Avg Loss: 0.987626 - Change in loss: 0.9876262684485742\n",
      "Epoch 2 step 71 - Learning Rate : 0.2- Avg Loss: 0.968867 - Change in loss: 0.9810052528514919\n",
      "Epoch 3 step 71 - Learning Rate : 0.2- Avg Loss: 0.978322 - Change in loss: 1.0097590331161888\n",
      "Epoch 4 step 71 - Learning Rate : 0.2- Avg Loss: 0.966762 - Change in loss: 0.9881843884216049\n",
      "Epoch 5 step 71 - Learning Rate : 0.2- Avg Loss: 0.966832 - Change in loss: 1.0000721153307741\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []\n",
    "epochs = []\n",
    "avg_loss = 1\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    if (epoch+1) % 10 ==0:\n",
    "        learning_rate /= 2\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    i = 0\n",
    "    losses = []\n",
    "    for evals, elo in data_loader:\n",
    "        evals = evals.to(device)\n",
    "\n",
    "        elo = elo.to(device)\n",
    "        i +=1\n",
    "        outputs = model(evals)\n",
    "        #print(outputs)\n",
    "        #print(outputs.shape, elo.shape)\n",
    "        loss = criterion(outputs,elo)\n",
    "\n",
    "        # optimizing\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    change = stats.mean(losses)/avg_loss\n",
    "    avg_loss = stats.mean(losses)\n",
    "    avg_losses.append(avg_loss)\n",
    "    epochs.append(epoch)\n",
    "    print(f'Epoch {epoch+1} step {i+1} - Learning Rate : {learning_rate}- Avg Loss: {avg_loss:3f} - Change in loss: {change}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why are 4/5 always zero???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(epochs, avg_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_data_loader = torch.utils.data.DataLoader(test_data_zip, batch_size=1, shuffle=False ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "outputs = []\n",
    "elos = []\n",
    "for evals, elo in test_data_loader:\n",
    "    #print(\"evals\",evals.shape)\n",
    "    evals = evals.to(device)\n",
    "    elo = elo.to(device)\n",
    "    output = model(evals)\n",
    "    outputs.append(output.item())\n",
    "    elos.append(elo.item())\n",
    "    loss = criterion(output,elo)\n",
    "    #print(f'Model prediction : {output} \\n ELO : {elo} \\n MSE : {loss}')\n",
    "    losses.append(loss.item())\n",
    "print(f'Average loss : {stats.mean(losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(elos,outputs, alpha = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the neural net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# note - to use any of these, I'm not sure that I can use the packed sequence. I would have to change the way the NN works, a little bit\n",
    "tb = SummaryWriter()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(max(outputs))\n",
    "print(min(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# note - doesn't support packed stuff\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tb.add_graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, no_layers):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.no_layers = no_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, no_layers, batch_first = True, bias = False)\n",
    "        self.fc = nn.Linear(hidden_size,1, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # initial hidden state\n",
    "        h0 = torch.rand(self.no_layers,x.size(0),self.hidden_size)\n",
    "\n",
    "        out, _ = self.rnn(x,h0)\n",
    "        #print(out) #return out\n",
    "        out = out[:,-1,:]\n",
    "        #print(out)\n",
    "        out = self.fc(out)\n",
    "        #print(out)\n",
    "        m = nn.Sigmoid()\n",
    "        out = m(out)\n",
    "        return out\n",
    "        # print(\"out: \",out)\n",
    "        # print('RNN WEIGHTS: ',self.rnn.weight_ih_l0  )\n",
    "        # print(self.fc.weight)\n",
    "        #\n",
    "        # #print(\"Count these...\",out)\n",
    "        # m = nn.Sigmoid()\n",
    "        # out = m(out)\n",
    "        # if x.size(0) == 1:\n",
    "        #     return out[0]\n",
    "        # else:\n",
    "        #     return torch.squeeze(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = MyRNN(input_size, hidden_size, no_layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
