{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from torchviz import make_dot\n",
    "from itertools import islice\n",
    "import torch\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import hiddenlayer as hl\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "outputs": [],
   "source": [
    "g = graphviz.Graph(engine='neato')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(str):\n",
    "    '''\n",
    "    :param str: string representing a list of centipawn losses\n",
    "    :return: list of integer centipawn losses\n",
    "    '''\n",
    "    string = str.replace('[','').replace(']','')\n",
    "    ls = string.split(',')\n",
    "    list = [int(i) for i in ls]\n",
    "\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(eval):\n",
    "    '''\n",
    "    :param eval: list of integer centipawn losses\n",
    "    :return: array of lists of [evaluation, centipawn loss]\n",
    "    '''\n",
    "\n",
    "    # starting evaluation of 30 centipawns\n",
    "    sum = 30\n",
    "\n",
    "    i = 0\n",
    "    res = []\n",
    "\n",
    "    # iterating through centipawn losses\n",
    "    for cpl in eval:\n",
    "\n",
    "        # subtracting the cpl for white's moves\n",
    "        if i % 2 ==0:\n",
    "            res.append([sum,cpl])\n",
    "            sum -= cpl\n",
    "            i += 1\n",
    "\n",
    "        # adding the cpl for black's moves\n",
    "        else:\n",
    "            sum+=cpl\n",
    "            i+=1\n",
    "\n",
    "    return numpy.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  games: 4210\n",
      "Evaluted games: 434\n"
     ]
    }
   ],
   "source": [
    "# reading *some* of the data\n",
    "dfs = []\n",
    "\n",
    "players = ['andreikin, dmitry', 'anand, viswanathan', 'wang, hao', 'grischuk, alexander', 'karjakin, sergey','duda, jan-krzysztof', 'radjabov, teimour', 'dominguez perez, leinier','nakamura, hikaru', 'vachier-lagrave, maxime','aronian, levon','mamedyarov, shakhriyar', 'so, wesley','ding, liren', 'rapport, richard', 'nepomniachtchi, ian', 'giri, anish', 'firouzja, alireza', 'caruana, fabiano','carlsen, magnus','zelcic, robert','khotenashvili, bela', 'bischoff, klaus', 'hoffmann, asa','kaufman, lawrence','bellaiche, elise']\n",
    "\n",
    "# reading the csvs\n",
    "for player in players:\n",
    "    df = pd.read_csv('blitz/'+player +'.csv')\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "\n",
    "print(f\"Total  games: {len(df)}\")\n",
    "\n",
    "# Filtering out * values\n",
    "df = df[df['WhiteELO'] != '*']\n",
    "df = df[df['BlackELO'] != '*']\n",
    "df[['WhiteELO', 'BlackELO']] = df[['WhiteELO', 'BlackELO']] .astype(int)\n",
    "\n",
    "df = df[df['Eval'] != '']\n",
    "df = df[ df['Eval'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "\n",
    "# converting the evaluation to a list\n",
    "df['Eval'] = df['Eval'].apply( to_list)\n",
    "df['Eval'] = df['Eval'].apply( process )\n",
    "\n",
    "print(f\"Evaluted games: {len(df['Eval'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.array(df['Eval'])\n",
    "length = numpy.array(df['Eval'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and fitting a power transformer\n",
    "pt = PowerTransformer()\n",
    "y = numpy.concatenate(x)\n",
    "pt.fit(y)\n",
    "transformed = pt.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a function now to (effieciently) change these to lists of length list\n",
    "transformed_array = [numpy.array(list(islice(iter(transformed), elem)))\n",
    "        for elem in length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique evaluated games: 422\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique evaluated games: {df['Game'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting evaluations and length to tensors\n",
    "evals = [torch.tensor(i, dtype = torch.float32) for i in transformed_array]\n",
    "lengths = [len(tensor) for tensor in evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding my sequences - not sure why batch first works, but it does\n",
    "#inputs = torch.nn.utils.rnn.pad_sequence(evals, batch_first=True, padding_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_array = numpy.array(inputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_list =inputs.tolist()\n",
    "\n",
    "# normalizing... a bit hacky\n",
    "#inputs_array = (numpy.array(inputs_list) - numpy.array(inputs_list).mean())/ numpy.linalg.norm(numpy.array(inputs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    '''\n",
    "    :param array:\n",
    "    :return:\n",
    "    '''\n",
    "    return (array - array.mean())/array.std()\n",
    "\n",
    "def denormalize(array, value):\n",
    "    '''\n",
    "    :param array:\n",
    "    :param value:\n",
    "    :return:\n",
    "    '''\n",
    "    return value*array.std() + array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['WhiteELO'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting White and Black's ELOs to tensors\n",
    "white_elo_arr = numpy.array(df['WhiteELO'])\n",
    "\n",
    "white_elo = normalize(white_elo_arr)\n",
    "\n",
    "#print(white_elo)\n",
    "white_elo = [torch.tensor(i, dtype = torch.float32) for i in white_elo]\n",
    "\n",
    "\n",
    "\n",
    "black_elo = numpy.array(df['BlackELO'])\n",
    "black_elo = [torch.tensor(i, dtype = torch.float32) for i in black_elo]\n",
    "\n",
    "\n",
    "# splitting into train and test\n",
    "lengths_train, lengths_test,eval_train, eval_test, black_train, black_test, white_train, white_test  = train_test_split(lengths, evals, black_elo, white_elo, test_size=0.2,random_state=0, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping the elo together with the evaluations\n",
    "train_data_zip = list(zip(eval_train, white_train))\n",
    "test_data_zip = list(zip(eval_test, white_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_elo = torch.stack(black_elo)\n",
    "white_elo = torch.stack(white_elo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, no_layers):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.no_layers = no_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, no_layers, batch_first = True, bias = True)\n",
    "        self.fc = nn.Linear(hidden_size,1, bias = False)\n",
    "        self.final = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out, _ = self.rnn(x)\n",
    "        output ,lengths = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first = True)\n",
    "        # shape batches, seq_length, hidden_size\n",
    "\n",
    "\n",
    "        out = [output[e, i-1,:].unsqueeze(0)for e, i in enumerate(lengths)]\n",
    "        out = torch.cat(out, dim = 0)\n",
    "        #print(out.shape)\n",
    "        #print(\"Linear weights\", self.fc.weight)\n",
    "        out = self.fc(out)\n",
    "        out = self.final(out)\n",
    "        #print(out.shape)\n",
    "        out = out[:,0]\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    #def init_hidden(self):\n",
    "    #    return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))\n",
    "\n",
    "# need to figure out exactly how the dimensions changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    '''\n",
    "    Yields a batch from a list of Items\n",
    "    Args:\n",
    "    test : Set True when using with test data loader. Defaults to False\n",
    "    percentile : Trim sequences by this percentile\n",
    "    '''\n",
    "\n",
    "    # remove that eventually. I'm going to need to make my dataset a tuple with evals and elo\n",
    "    #def __init__(self):\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        data = [item[0] for item in batch]\n",
    "        target = [item[1] for item in batch]\n",
    "        lens = [i.shape[0] for i in data]\n",
    "\n",
    "        #print(lens)\n",
    "        data = torch.nn.utils.rnn.pad_sequence(data, batch_first=True,padding_value = 0)\n",
    "        #data = data.unsqueeze(2)\n",
    "        #print(\"PADDED\",data)\n",
    "        evals_packed = torch.nn.utils.rnn.pack_padded_sequence(data,batch_first = True, lengths=lens,enforce_sorted=False)\n",
    "\n",
    "        target = torch.tensor(target,dtype=torch.float32)\n",
    "        return [evals_packed,target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 45\n",
    "no_layers = 4\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (defining my model)\n",
    "model = MyRNN(input_size, hidden_size, no_layers)\n",
    "collate = MyCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MyRNN(\n",
      "  (rnn): RNN(2, 45, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=45, out_features=1, bias=False)\n",
      "  (final): Tanh()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/h45l4-2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "outputs": [],
   "source": [
    "# # add to loop\n",
    "# running_loss  = 0\n",
    "# running_loss += loss.item()\n",
    "# writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps +i)\n",
    "# writer.add_scalar('accuracy', running_loss / 100, epoch * n_total_steps +i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_data_zip, batch_size=batch_size, shuffle=True ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK I've figured out the issue, I also need the sequence length for the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 step 71 - Learning Rate : 0.2- Avg Loss: 1.014039 - Change in loss: 1.014038607265268\n",
      "Epoch 2 step 71 - Learning Rate : 0.2- Avg Loss: 1.013356 - Change in loss: 0.9993265126804687\n",
      "Epoch 3 step 71 - Learning Rate : 0.2- Avg Loss: 0.972887 - Change in loss: 0.9600646675921398\n",
      "Epoch 4 step 71 - Learning Rate : 0.2- Avg Loss: 0.974905 - Change in loss: 1.002073841084142\n",
      "Epoch 5 step 71 - Learning Rate : 0.2- Avg Loss: 1.087434 - Change in loss: 1.1154260816360735\n",
      "Epoch 6 step 71 - Learning Rate : 0.2- Avg Loss: 0.978146 - Change in loss: 0.8994992475874153\n",
      "Epoch 7 step 71 - Learning Rate : 0.2- Avg Loss: 0.989962 - Change in loss: 1.0120797631120355\n",
      "Epoch 8 step 71 - Learning Rate : 0.2- Avg Loss: 0.963583 - Change in loss: 0.9733535117015311\n",
      "Epoch 9 step 71 - Learning Rate : 0.2- Avg Loss: 0.964566 - Change in loss: 1.0010201011279602\n",
      "Epoch 10 step 71 - Learning Rate : 0.1- Avg Loss: 0.966958 - Change in loss: 1.0024803963334656\n",
      "Epoch 11 step 71 - Learning Rate : 0.1- Avg Loss: 0.964125 - Change in loss: 0.9970701940485563\n",
      "Epoch 12 step 71 - Learning Rate : 0.1- Avg Loss: 0.967193 - Change in loss: 1.0031823735147543\n",
      "Epoch 13 step 71 - Learning Rate : 0.1- Avg Loss: 0.965393 - Change in loss: 0.9981383650991354\n",
      "Epoch 14 step 71 - Learning Rate : 0.1- Avg Loss: 0.965253 - Change in loss: 0.9998550703837371\n",
      "Epoch 15 step 71 - Learning Rate : 0.1- Avg Loss: 0.964535 - Change in loss: 0.9992562245962806\n",
      "Epoch 16 step 71 - Learning Rate : 0.1- Avg Loss: 0.970030 - Change in loss: 1.0056973630123611\n",
      "Epoch 17 step 71 - Learning Rate : 0.1- Avg Loss: 0.965274 - Change in loss: 0.9950969552890364\n",
      "Epoch 18 step 71 - Learning Rate : 0.1- Avg Loss: 1.058281 - Change in loss: 1.0963527793237307\n",
      "Epoch 19 step 71 - Learning Rate : 0.1- Avg Loss: 0.964225 - Change in loss: 0.9111236622779397\n",
      "Epoch 20 step 71 - Learning Rate : 0.05- Avg Loss: 0.960124 - Change in loss: 0.9957467189303003\n",
      "Epoch 21 step 71 - Learning Rate : 0.05- Avg Loss: 0.975774 - Change in loss: 1.0162999889480906\n",
      "Epoch 22 step 71 - Learning Rate : 0.05- Avg Loss: 0.958336 - Change in loss: 0.982129366069613\n",
      "Epoch 23 step 71 - Learning Rate : 0.05- Avg Loss: 0.975983 - Change in loss: 1.0184138167891734\n",
      "Epoch 24 step 71 - Learning Rate : 0.05- Avg Loss: 0.958938 - Change in loss: 0.9825359234451326\n",
      "Epoch 25 step 71 - Learning Rate : 0.05- Avg Loss: 0.958722 - Change in loss: 0.9997741714184107\n",
      "Epoch 26 step 71 - Learning Rate : 0.05- Avg Loss: 0.956719 - Change in loss: 0.9979107013854925\n",
      "Epoch 27 step 71 - Learning Rate : 0.05- Avg Loss: 0.960399 - Change in loss: 1.0038467606035033\n",
      "Epoch 28 step 71 - Learning Rate : 0.05- Avg Loss: 0.951279 - Change in loss: 0.9905042114215242\n",
      "Epoch 29 step 71 - Learning Rate : 0.05- Avg Loss: 0.954616 - Change in loss: 1.0035073984991445\n",
      "Epoch 30 step 71 - Learning Rate : 0.025- Avg Loss: 0.955954 - Change in loss: 1.0014020614606256\n",
      "Epoch 31 step 71 - Learning Rate : 0.025- Avg Loss: 0.950489 - Change in loss: 0.9942832197386193\n",
      "Epoch 32 step 71 - Learning Rate : 0.025- Avg Loss: 0.946422 - Change in loss: 0.995721165662621\n",
      "Epoch 33 step 71 - Learning Rate : 0.025- Avg Loss: 0.963870 - Change in loss: 1.018435409841864\n",
      "Epoch 34 step 71 - Learning Rate : 0.025- Avg Loss: 0.947818 - Change in loss: 0.9833460528293891\n",
      "Epoch 35 step 71 - Learning Rate : 0.025- Avg Loss: 0.949496 - Change in loss: 1.0017704877231128\n",
      "Epoch 36 step 71 - Learning Rate : 0.025- Avg Loss: 0.951980 - Change in loss: 1.0026160768977375\n",
      "Epoch 37 step 71 - Learning Rate : 0.025- Avg Loss: 0.962576 - Change in loss: 1.0111309156268953\n",
      "Epoch 38 step 71 - Learning Rate : 0.025- Avg Loss: 0.947579 - Change in loss: 0.9844203355890646\n",
      "Epoch 39 step 71 - Learning Rate : 0.025- Avg Loss: 0.944587 - Change in loss: 0.996842461608947\n",
      "Epoch 40 step 71 - Learning Rate : 0.0125- Avg Loss: 0.938751 - Change in loss: 0.9938207951535418\n",
      "Epoch 41 step 71 - Learning Rate : 0.0125- Avg Loss: 0.936670 - Change in loss: 0.9977834892401197\n",
      "Epoch 42 step 71 - Learning Rate : 0.0125- Avg Loss: 0.941522 - Change in loss: 1.0051802506885588\n",
      "Epoch 43 step 71 - Learning Rate : 0.0125- Avg Loss: 0.937458 - Change in loss: 0.9956839043960218\n",
      "Epoch 44 step 71 - Learning Rate : 0.0125- Avg Loss: 0.934175 - Change in loss: 0.9964971909541593\n",
      "Epoch 45 step 71 - Learning Rate : 0.0125- Avg Loss: 0.974152 - Change in loss: 1.0427944967058316\n",
      "Epoch 46 step 71 - Learning Rate : 0.0125- Avg Loss: 0.933561 - Change in loss: 0.9583319256050223\n",
      "Epoch 47 step 71 - Learning Rate : 0.0125- Avg Loss: 0.932938 - Change in loss: 0.9993327195941448\n",
      "Epoch 48 step 71 - Learning Rate : 0.0125- Avg Loss: 0.936078 - Change in loss: 1.0033660346370088\n",
      "Epoch 49 step 71 - Learning Rate : 0.0125- Avg Loss: 0.933879 - Change in loss: 0.9976503701242196\n",
      "Epoch 50 step 71 - Learning Rate : 0.00625- Avg Loss: 0.925624 - Change in loss: 0.9911605944425218\n",
      "Epoch 51 step 71 - Learning Rate : 0.00625- Avg Loss: 0.927805 - Change in loss: 1.0023560817896486\n",
      "Epoch 52 step 71 - Learning Rate : 0.00625- Avg Loss: 0.924597 - Change in loss: 0.9965427076745651\n",
      "Epoch 53 step 71 - Learning Rate : 0.00625- Avg Loss: 0.921526 - Change in loss: 0.9966787716609324\n",
      "Epoch 54 step 71 - Learning Rate : 0.00625- Avg Loss: 0.948888 - Change in loss: 1.02969115184028\n",
      "Epoch 55 step 71 - Learning Rate : 0.00625- Avg Loss: 0.923095 - Change in loss: 0.9728178133960225\n",
      "Epoch 56 step 71 - Learning Rate : 0.00625- Avg Loss: 0.921352 - Change in loss: 0.998112403946978\n",
      "Epoch 57 step 71 - Learning Rate : 0.00625- Avg Loss: 0.921900 - Change in loss: 1.0005948776205893\n",
      "Epoch 58 step 71 - Learning Rate : 0.00625- Avg Loss: 0.923963 - Change in loss: 1.0022368863883435\n",
      "Epoch 59 step 71 - Learning Rate : 0.00625- Avg Loss: 0.923790 - Change in loss: 0.9998128353971779\n",
      "Epoch 60 step 71 - Learning Rate : 0.003125- Avg Loss: 0.914074 - Change in loss: 0.9894833265072908\n",
      "Epoch 61 step 71 - Learning Rate : 0.003125- Avg Loss: 0.920326 - Change in loss: 1.0068392444496936\n",
      "Epoch 62 step 71 - Learning Rate : 0.003125- Avg Loss: 0.915042 - Change in loss: 0.9942589006842938\n",
      "Epoch 63 step 71 - Learning Rate : 0.003125- Avg Loss: 0.918739 - Change in loss: 1.0040402215649327\n",
      "Epoch 64 step 71 - Learning Rate : 0.003125- Avg Loss: 0.912226 - Change in loss: 0.9929109810234734\n",
      "Epoch 65 step 71 - Learning Rate : 0.003125- Avg Loss: 0.915007 - Change in loss: 1.0030485425094133\n",
      "Epoch 66 step 71 - Learning Rate : 0.003125- Avg Loss: 0.938010 - Change in loss: 1.025139625552756\n",
      "Epoch 67 step 71 - Learning Rate : 0.003125- Avg Loss: 0.914814 - Change in loss: 0.975270765775639\n",
      "Epoch 68 step 71 - Learning Rate : 0.003125- Avg Loss: 0.912035 - Change in loss: 0.9969617596219926\n",
      "Epoch 69 step 71 - Learning Rate : 0.003125- Avg Loss: 0.912071 - Change in loss: 1.0000402303862088\n",
      "Epoch 70 step 71 - Learning Rate : 0.0015625- Avg Loss: 0.908551 - Change in loss: 0.9961400350528566\n",
      "Epoch 71 step 71 - Learning Rate : 0.0015625- Avg Loss: 0.909797 - Change in loss: 1.0013720605719638\n",
      "Epoch 72 step 71 - Learning Rate : 0.0015625- Avg Loss: 0.911043 - Change in loss: 1.0013689375861141\n",
      "Epoch 73 step 71 - Learning Rate : 0.0015625- Avg Loss: 0.953956 - Change in loss: 1.0471037170155955\n",
      "Epoch 74 step 71 - Learning Rate : 0.0015625- Avg Loss: 0.917027 - Change in loss: 0.9612878889005215\n",
      "Epoch 75 step 71 - Learning Rate : 0.0015625- Avg Loss: 0.908633 - Change in loss: 0.9908464681689838\n",
      "Epoch 76 step 71 - Learning Rate : 0.0015625- Avg Loss: 0.906739 - Change in loss: 0.9979161536155188\n",
      "Epoch 77 step 71 - Learning Rate : 0.0015625- Avg Loss: 0.907956 - Change in loss: 1.0013420312277852\n",
      "Epoch 78 step 71 - Learning Rate : 0.0015625- Avg Loss: 0.906925 - Change in loss: 0.9988644688539742\n",
      "Epoch 79 step 71 - Learning Rate : 0.0015625- Avg Loss: 0.907471 - Change in loss: 1.0006015723410653\n",
      "Epoch 80 step 71 - Learning Rate : 0.00078125- Avg Loss: 0.904195 - Change in loss: 0.9963902861556964\n",
      "Epoch 81 step 71 - Learning Rate : 0.00078125- Avg Loss: 0.926503 - Change in loss: 1.0246717405320587\n",
      "Epoch 82 step 71 - Learning Rate : 0.00078125- Avg Loss: 0.904839 - Change in loss: 0.9766173464428951\n",
      "Epoch 83 step 71 - Learning Rate : 0.00078125- Avg Loss: 0.902992 - Change in loss: 0.9979590673693024\n",
      "Epoch 84 step 71 - Learning Rate : 0.00078125- Avg Loss: 0.907263 - Change in loss: 1.0047297269105344\n",
      "Epoch 85 step 71 - Learning Rate : 0.00078125- Avg Loss: 0.906099 - Change in loss: 0.9987165986678077\n",
      "Epoch 86 step 71 - Learning Rate : 0.00078125- Avg Loss: 0.902121 - Change in loss: 0.9956099158647624\n",
      "Epoch 87 step 71 - Learning Rate : 0.00078125- Avg Loss: 0.903616 - Change in loss: 1.001657517711359\n",
      "Epoch 88 step 71 - Learning Rate : 0.00078125- Avg Loss: 0.905203 - Change in loss: 1.0017560754691697\n",
      "Epoch 89 step 71 - Learning Rate : 0.00078125- Avg Loss: 0.902982 - Change in loss: 0.9975463347034369\n",
      "Epoch 90 step 71 - Learning Rate : 0.000390625- Avg Loss: 0.947011 - Change in loss: 1.0487599449525862\n",
      "Epoch 91 step 71 - Learning Rate : 0.000390625- Avg Loss: 0.902912 - Change in loss: 0.9534335331904763\n",
      "Epoch 92 step 71 - Learning Rate : 0.000390625- Avg Loss: 0.921610 - Change in loss: 1.020708234667573\n",
      "Epoch 93 step 71 - Learning Rate : 0.000390625- Avg Loss: 0.902561 - Change in loss: 0.9793313872662285\n",
      "Epoch 94 step 71 - Learning Rate : 0.000390625- Avg Loss: 0.906842 - Change in loss: 1.004742434924824\n",
      "Epoch 95 step 71 - Learning Rate : 0.000390625- Avg Loss: 0.901548 - Change in loss: 0.9941621211256431\n",
      "Epoch 96 step 71 - Learning Rate : 0.000390625- Avg Loss: 0.901885 - Change in loss: 1.0003735281532145\n",
      "Epoch 97 step 71 - Learning Rate : 0.000390625- Avg Loss: 0.902496 - Change in loss: 1.0006778356216883\n",
      "Epoch 98 step 71 - Learning Rate : 0.000390625- Avg Loss: 0.902681 - Change in loss: 1.0002048146026092\n",
      "Epoch 99 step 71 - Learning Rate : 0.000390625- Avg Loss: 0.900406 - Change in loss: 0.9974799571406703\n",
      "Epoch 100 step 71 - Learning Rate : 0.0001953125- Avg Loss: 0.898520 - Change in loss: 0.9979053315877892\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []\n",
    "epochs = []\n",
    "avg_loss = 1\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    if (epoch+1) % 10 ==0:\n",
    "        learning_rate /= 2\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    i = 0\n",
    "    for evals, elo in data_loader:\n",
    "        evals = evals.to(device)\n",
    "        elo = elo.to(device)\n",
    "        outputs = model(evals)\n",
    "        #print(outputs)\n",
    "        #print(outputs.shape, elo.shape)\n",
    "        loss = criterion(outputs,elo)\n",
    "        # optimizing\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        i+=1\n",
    "\n",
    "    change = stats.mean(losses)/avg_loss\n",
    "    avg_loss = stats.mean(losses)\n",
    "\n",
    "    # adding histograms to the summary writer\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(name, np.array(param.detach().tolist()), epoch)\n",
    "\n",
    "    # adding loss\n",
    "    writer.add_scalar('Average loss',avg_loss, epoch)\n",
    "    avg_losses.append(avg_loss)\n",
    "    epochs.append(epoch)\n",
    "    print(f'Epoch {epoch+1} step {i+1} - Learning Rate : {learning_rate}- Avg Loss: {avg_loss:3f} - Change in loss: {change}')\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x1ea99b1eda0>"
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(epochs, avg_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "outputs": [],
   "source": [
    "model =model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "MyRNN(\n  (rnn): RNN(2, 45, num_layers=4, batch_first=True)\n  (fc): Linear(in_features=45, out_features=1, bias=False)\n  (final): Tanh()\n)"
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = torch.utils.data.DataLoader(test_data_zip, batch_size=1, shuffle=False ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss : 1.1921558537826227\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "outputs = []\n",
    "elos = []\n",
    "for evals, elo in test_data_loader:\n",
    "    #print(\"evals\",evals.shape)\n",
    "    evals = evals.to(device)\n",
    "    elo = elo.to(device)\n",
    "    output = model(evals)\n",
    "    outputs.append(output.item())\n",
    "    elos.append(elo.item())\n",
    "    loss = criterion(output,elo)\n",
    "    #print(f'Model prediction : {output} \\n ELO : {elo} \\n MSE : {loss}')\n",
    "    losses.append(loss.item())\n",
    "print(f'Average loss : {stats.mean(losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.1588], grad_fn=<SelectBackward0>)"
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x1ea99ae1c90>"
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(elos,outputs, alpha = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the neural net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5265672206878662\n",
      "-0.8018124103546143\n"
     ]
    }
   ],
   "source": [
    "print(max(outputs))\n",
    "print(min(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "outputs": [],
   "source": [
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "#traced_script_module = torch.jit.trace(model, example)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "outputs": [],
   "source": [
    "params =dict(model.named_parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "outputs": [],
   "source": [
    "dot = make_dot(output, params=params, show_attrs=False, show_saved=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "outputs": [
    {
     "data": {
      "text/plain": "'rnn_torchviz3.pdf'"
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot.render(\"rnn_torchviz3\", format=\"pdf\", engine= 'neato') # doesn't seem to work great with padded & packed input..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/run1')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
