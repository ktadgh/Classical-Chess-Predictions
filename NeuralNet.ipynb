{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from torchviz import make_dot\n",
    "from itertools import islice\n",
    "import torch\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import hiddenlayer as hl\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "g = graphviz.Graph(engine='neato')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(str):\n",
    "    '''\n",
    "    :param str: string representing a list of centipawn losses\n",
    "    :return: list of integer centipawn losses\n",
    "    '''\n",
    "    string = str.replace('[','').replace(']','')\n",
    "    ls = string.split(',')\n",
    "    list = [int(i) for i in ls]\n",
    "\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def black_process(eval):\n",
    "    '''\n",
    "    :param eval: list of integer centipawn losses\n",
    "    :return: array of lists of [evaluation, centipawn loss]\n",
    "    '''\n",
    "\n",
    "    # starting evaluation of 30 centipawns\n",
    "    sum = 30\n",
    "\n",
    "    i = 0\n",
    "    res = []\n",
    "\n",
    "    # iterating through centipawn losses\n",
    "    for cpl in eval:\n",
    "\n",
    "        # subtracting the cpl for white's moves\n",
    "        if i % 2 ==0:\n",
    "            sum -= cpl\n",
    "            i += 1\n",
    "\n",
    "        # adding the cpl for black's moves\n",
    "        else:\n",
    "            res.append([sum,cpl])\n",
    "            sum+=cpl\n",
    "            i+=1\n",
    "\n",
    "    return numpy.array(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_process(eval):\n",
    "    '''\n",
    "    :param eval: list of integer centipawn losses\n",
    "    :return: array of lists of [evaluation, centipawn loss]\n",
    "    '''\n",
    "\n",
    "    # starting evaluation of 30 centipawns\n",
    "    sum = 30\n",
    "\n",
    "    i = 0\n",
    "    res = []\n",
    "\n",
    "    # iterating through centipawn losses\n",
    "    for cpl in eval:\n",
    "\n",
    "        # subtracting the cpl for white's moves\n",
    "        if i % 2 ==0:\n",
    "            res.append([sum,cpl])\n",
    "            sum -= cpl\n",
    "            i += 1\n",
    "\n",
    "        # adding the cpl for black's moves\n",
    "        else:\n",
    "            sum+=cpl\n",
    "            i+=1\n",
    "\n",
    "    return numpy.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  games: 4469\n",
      "Evaluted games: 458\n"
     ]
    }
   ],
   "source": [
    "# reading *some* of the data\n",
    "dfs = []\n",
    "\n",
    "players = ['andreikin, dmitry', 'anand, viswanathan', 'wang, hao', 'grischuk, alexander', 'karjakin, sergey','duda, jan-krzysztof', 'radjabov, teimour', 'dominguez perez, leinier','nakamura, hikaru', 'vachier-lagrave, maxime','aronian, levon','mamedyarov, shakhriyar', 'so, wesley','ding, liren', 'rapport, richard', 'nepomniachtchi, ian', 'giri, anish', 'firouzja, alireza', 'caruana, fabiano','carlsen, magnus','zelcic, robert','khotenashvili, bela', 'bischoff, klaus', 'hoffmann, asa','kaufman, lawrence','bellaiche, elise']\n",
    "\n",
    "# reading the csvs\n",
    "for player in players:\n",
    "    df = pd.read_csv('blitz/'+player +'.csv')\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "\n",
    "print(f\"Total  games: {len(df)}\")\n",
    "\n",
    "# Filtering out * values\n",
    "df = df[df['WhiteELO'] != '*']\n",
    "df = df[df['BlackELO'] != '*']\n",
    "df[['WhiteELO', 'BlackELO']] = df[['WhiteELO', 'BlackELO']] .astype(int)\n",
    "\n",
    "df = df[df['Eval'] != '']\n",
    "df = df[ df['Eval'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "\n",
    "# converting the evaluation to a list\n",
    "df['Eval'] = df['Eval'].apply( to_list)\n",
    "df['WhiteEval'] = df['Eval'].apply( white_process )\n",
    "df['BlackEval'] = df['Eval'].apply( black_process )\n",
    "\n",
    "print(f\"Evaluted games: {len(df['Eval'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_x = numpy.array(df['WhiteEval'])\n",
    "white_length = numpy.array(df['WhiteEval'].apply(len))\n",
    "\n",
    "black_x = numpy.array(df['WhiteEval'])\n",
    "black_length = numpy.array(df['WhiteEval'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and fitting a power transformer for black and white\n",
    "wpt = PowerTransformer()\n",
    "white_y = numpy.concatenate(white_x)\n",
    "wpt.fit(white_y)\n",
    "white_transformed = wpt.transform(white_y)\n",
    "\n",
    "bpt = PowerTransformer()\n",
    "black_y = numpy.concatenate(black_x)\n",
    "bpt.fit(black_y)\n",
    "black_transformed = bpt.transform(black_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a function now to (effieciently) change these to lists of length list\n",
    "white_transformed_array = [numpy.array(list(islice(iter(white_transformed), elem)))\n",
    "        for elem in white_length]\n",
    "\n",
    "black_transformed_array = [numpy.array(list(islice(iter(black_transformed), elem)))\n",
    "        for elem in black_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique evaluated games: 446\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique evaluated games: {df['Game'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_472\\4203895052.py:2: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  white_evals = [torch.tensor(i, dtype = torch.float32) for i in white_transformed_array]\n"
     ]
    }
   ],
   "source": [
    "# converting evaluations and length to tensors\n",
    "white_evals = [torch.tensor(i, dtype = torch.float32) for i in white_transformed_array]\n",
    "white_lengths = [len(tensor) for tensor in white_evals]\n",
    "\n",
    "black_evals = [torch.tensor(i, dtype = torch.float32) for i in black_transformed_array]\n",
    "black_lengths = [len(tensor) for tensor in black_evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding my sequences - not sure why batch first works, but it does\n",
    "#inputs = torch.nn.utils.rnn.pad_sequence(evals, batch_first=True, padding_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_array = numpy.array(inputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_list =inputs.tolist()\n",
    "\n",
    "# normalizing... a bit hacky\n",
    "#inputs_array = (numpy.array(inputs_list) - numpy.array(inputs_list).mean())/ numpy.linalg.norm(numpy.array(inputs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    '''\n",
    "    :param array:\n",
    "    :return:\n",
    "    '''\n",
    "    return (array - array.mean())/array.std()\n",
    "\n",
    "def denormalize(array, value):\n",
    "    '''\n",
    "    :param array:\n",
    "    :param value:\n",
    "    :return:\n",
    "    '''\n",
    "    return value*array.std() + array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['WhiteELO'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting White and Black's ELOs to tensors\n",
    "white_elo_arr = numpy.array(df['WhiteELO'])\n",
    "\n",
    "white_elo = normalize(white_elo_arr)\n",
    "\n",
    "#print(white_elo)\n",
    "white_elo = [torch.tensor(i, dtype = torch.float32) for i in white_elo]\n",
    "\n",
    "\n",
    "\n",
    "black_elo = numpy.array(df['BlackELO'])\n",
    "black_elo = [torch.tensor(i, dtype = torch.float32) for i in black_elo]\n",
    "\n",
    "\n",
    "# splitting into train and test\n",
    "#lengths_train, lengths_test,white_eval_train, white_eval_test, black_eval_train, black_eval_test, black_train, black_test, white_train, white_test  = train_test_split(lengths, white_evals, black_evals, black_elo, white_elo, test_size=0.2,random_state=0, shuffle = True)\n",
    "white_eval_train, white_eval_test, black_eval_train, black_eval_test, black_train, black_test, white_train, white_test  = train_test_split(white_evals, black_evals, black_elo, white_elo, test_size=0.2,random_state=0, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping the elo together with the evaluations\n",
    "train_data_zip = list(zip(white_eval_train, black_eval_train, white_train))\n",
    "test_data_zip = list(zip(white_eval_test, black_eval_test, white_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_elo = torch.stack(black_elo)\n",
    "white_elo = torch.stack(white_elo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, no_layers):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.no_layers = no_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, no_layers, batch_first = True, bias = True)\n",
    "        self.fc = nn.Linear(hidden_size,1, bias = False)\n",
    "        self.final = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out, _ = self.rnn(x)\n",
    "        output ,lengths = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first = True)\n",
    "        # shape batches, seq_length, hidden_size\n",
    "\n",
    "\n",
    "        out = [output[e, i-1,:].unsqueeze(0)for e, i in enumerate(lengths)]\n",
    "        out = torch.cat(out, dim = 0)\n",
    "        #print(out.shape)\n",
    "        #print(\"Linear weights\", self.fc.weight)\n",
    "        out = self.fc(out)\n",
    "        out = self.final(out)\n",
    "        #print(out.shape)\n",
    "        out = out[:,0]\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    #def init_hidden(self):\n",
    "    #    return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))\n",
    "\n",
    "# need to figure out exactly how the dimensions changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    '''\n",
    "    Yields a batch from a list of Items\n",
    "    Args:\n",
    "    test : Set True when using with test data loader. Defaults to False\n",
    "    percentile : Trim sequences by this percentile\n",
    "    '''\n",
    "\n",
    "    # remove that eventually. I'm going to need to make my dataset a tuple with evals and elo\n",
    "    #def __init__(self):\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        white_data = [item[0] for item in batch]\n",
    "        black_data = [item[1] for item in batch]\n",
    "        target = [item[2] for item in batch]\n",
    "        white_lens = [i.shape[0] for i in white_data]\n",
    "        black_lens = [i.shape[0] for i in black_data]\n",
    "\n",
    "\n",
    "        white_data = torch.nn.utils.rnn.pad_sequence(white_data, batch_first=True,padding_value = 0)\n",
    "        white_evals_packed = torch.nn.utils.rnn.pack_padded_sequence(white_data,batch_first = True, lengths=white_lens,enforce_sorted=False)\n",
    "\n",
    "        black_data = torch.nn.utils.rnn.pad_sequence(black_data, batch_first=True,padding_value = 0)\n",
    "        black_evals_packed = torch.nn.utils.rnn.pack_padded_sequence(black_data,batch_first = True, lengths=black_lens,enforce_sorted=False)\n",
    "\n",
    "\n",
    "        target = torch.tensor(target,dtype=torch.float32)\n",
    "        return [white_evals_packed, black_evals_packed,target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 45\n",
    "no_layers = 4\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (defining my model)\n",
    "model = MyRNN(input_size, hidden_size, no_layers)\n",
    "collate = MyCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MyRNN(\n",
      "  (rnn): RNN(2, 45, num_layers=4, batch_first=True)\n",
      "  (fc): Linear(in_features=45, out_features=1, bias=False)\n",
      "  (final): Tanh()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/h45l4-2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# # add to loop\n",
    "# running_loss  = 0\n",
    "# running_loss += loss.item()\n",
    "# writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps +i)\n",
    "# writer.add_scalar('accuracy', running_loss / 100, epoch * n_total_steps +i)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_data_zip, batch_size=batch_size, shuffle=True ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK I've figured out the issue, I also need the sequence length for the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 step 75 - Learning Rate : 0.2- Avg Loss: 2.092240 - Change in loss: 2.0922403593321106\n",
      "Epoch 2 step 75 - Learning Rate : 0.2- Avg Loss: 2.036663 - Change in loss: 0.9734365951843378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []\n",
    "epochs = []\n",
    "avg_loss = 1\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    if (epoch+1) % 10 ==0:\n",
    "        learning_rate /= 2\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    i = 0\n",
    "    for white_evals, black_evals, elo in data_loader:\n",
    "        white_evals = white_evals.to(device)\n",
    "        black_evals = black_evals.to(device)\n",
    "        elo = elo.to(device)\n",
    "        outputs = model(white_evals)\n",
    "        #print(outputs)\n",
    "        #print(outputs.shape, elo.shape)\n",
    "        loss = criterion(outputs,elo)\n",
    "        # optimizing\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        i+=1\n",
    "\n",
    "    change = stats.mean(losses)/avg_loss\n",
    "    avg_loss = stats.mean(losses)\n",
    "\n",
    "    # adding histograms to the summary writer\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(name, np.array(param.detach().tolist()), epoch)\n",
    "\n",
    "    # adding loss\n",
    "    writer.add_scalar('Average loss',avg_loss, epoch)\n",
    "    avg_losses.append(avg_loss)\n",
    "    epochs.append(epoch)\n",
    "    print(f'Epoch {epoch+1} step {i+1} - Learning Rate : {learning_rate}- Avg Loss: {avg_loss:3f} - Change in loss: {change}')\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(epochs, avg_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model =model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = torch.utils.data.DataLoader(test_data_zip, batch_size=1, shuffle=False ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "outputs = []\n",
    "elos = []\n",
    "for evals, elo in test_data_loader:\n",
    "    #print(\"evals\",evals.shape)\n",
    "    evals = evals.to(device)\n",
    "    elo = elo.to(device)\n",
    "    output = model(evals)\n",
    "    outputs.append(output.item())\n",
    "    elos.append(elo.item())\n",
    "    loss = criterion(output,elo)\n",
    "    #print(f'Model prediction : {output} \\n ELO : {elo} \\n MSE : {loss}')\n",
    "    losses.append(loss.item())\n",
    "print(f'Average loss : {stats.mean(losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(elos,outputs, alpha = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the neural net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(outputs))\n",
    "print(min(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "#traced_script_module = torch.jit.trace(model, example)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params =dict(model.named_parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dot = make_dot(output, params=params, show_attrs=False, show_saved=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dot.render(\"rnn_torchviz3\", format=\"pdf\", engine= 'neato') # doesn't seem to work great with padded & packed input..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/run1')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
