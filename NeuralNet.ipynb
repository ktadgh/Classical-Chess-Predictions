{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from torchviz import make_dot\n",
    "from itertools import islice\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import hiddenlayer as hl\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "g = graphviz.Graph(engine='neato')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(str):\n",
    "    '''\n",
    "    :param str: string representing a list of centipawn losses\n",
    "    :return: list of integer centipawn losses\n",
    "    '''\n",
    "    string = str.replace('[','').replace(']','')\n",
    "    ls = string.split(',')\n",
    "    list = [int(i) for i in ls]\n",
    "\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(eval):\n",
    "    '''\n",
    "    :param eval: list of integer centipawn losses\n",
    "    :return: array of lists of [evaluation, centipawn loss]\n",
    "    '''\n",
    "\n",
    "    # starting evaluation of 30 centipawns\n",
    "    sum = 30\n",
    "\n",
    "    i = 0\n",
    "    res = []\n",
    "\n",
    "    # iterating through centipawn losses\n",
    "    for cpl in eval:\n",
    "\n",
    "        # subtracting the cpl for white's moves\n",
    "        if i % 2 ==0:\n",
    "            res.append([sum,cpl])\n",
    "            sum -= cpl\n",
    "            i += 1\n",
    "\n",
    "        # adding the cpl for black's moves\n",
    "        else:\n",
    "            sum+=cpl\n",
    "            i+=1\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  games: 4210\n",
      "Evaluted games: 434\n"
     ]
    }
   ],
   "source": [
    "# reading *some* of the data\n",
    "dfs = []\n",
    "\n",
    "players = ['andreikin, dmitry', 'anand, viswanathan', 'wang, hao', 'grischuk, alexander', 'karjakin, sergey','duda, jan-krzysztof', 'radjabov, teimour', 'dominguez perez, leinier','nakamura, hikaru', 'vachier-lagrave, maxime','aronian, levon','mamedyarov, shakhriyar', 'so, wesley','ding, liren', 'rapport, richard', 'nepomniachtchi, ian', 'giri, anish', 'firouzja, alireza', 'caruana, fabiano','carlsen, magnus','zelcic, robert','khotenashvili, bela', 'bischoff, klaus', 'hoffmann, asa','kaufman, lawrence','bellaiche, elise']\n",
    "\n",
    "# reading the csvs\n",
    "for player in players:\n",
    "    df = pd.read_csv('blitz/'+player +'.csv')\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "\n",
    "print(f\"Total  games: {len(df)}\")\n",
    "\n",
    "# Filtering out * values\n",
    "df = df[df['WhiteELO'] != '*']\n",
    "df = df[df['BlackELO'] != '*']\n",
    "df[['WhiteELO', 'BlackELO']] = df[['WhiteELO', 'BlackELO']] .astype(int)\n",
    "\n",
    "df = df[df['Eval'] != '']\n",
    "df = df[ df['Eval'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "\n",
    "# converting the evaluation to a list\n",
    "df['Eval'] = df['Eval'].apply( to_list)\n",
    "df['Eval'] = df['Eval'].apply( process )\n",
    "\n",
    "print(f\"Evaluted games: {len(df['Eval'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df['Eval'])\n",
    "length = np.array(df['Eval'].apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and fitting a power transformer\n",
    "pt = PowerTransformer()\n",
    "y = np.concatenate(x)\n",
    "pt.fit(y)\n",
    "transformed = pt.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a function now to (effieciently) change these to lists of length list\n",
    "transformed_array = [np.array(list(islice(iter(transformed), elem)))\n",
    "        for elem in length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique evaluated games: 422\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique evaluated games: {df['Game'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_6800\\1911683741.py:2: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:77.)\n",
      "  evals = [torch.tensor(i, dtype = torch.float32) for i in transformed_array]\n"
     ]
    }
   ],
   "source": [
    "# converting evaluations and length to tensors\n",
    "evals = [torch.tensor(i, dtype = torch.float32) for i in transformed_array]\n",
    "lengths = [len(tensor) for tensor in evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding my sequences - not sure why batch first works, but it does\n",
    "#inputs = torch.nn.utils.rnn.pad_sequence(evals, batch_first=True, padding_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_array = np.array(inputs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs_list =inputs.tolist()\n",
    "\n",
    "# normalizing... a bit hacky\n",
    "#inputs_array = (np.array(inputs_list) - np.array(inputs_list).mean())/ np.linalg.norm(np.array(inputs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    '''\n",
    "    :param array:\n",
    "    :return:\n",
    "    '''\n",
    "    return (array - array.mean())/array.std()\n",
    "\n",
    "def denormalize(array, value):\n",
    "    '''\n",
    "    :param array:\n",
    "    :param value:\n",
    "    :return:\n",
    "    '''\n",
    "    return value*array.std() + array.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['WhiteELO'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting White and Black's ELOs to tensors\n",
    "white_elo_arr = np.array(df['WhiteELO'])\n",
    "\n",
    "white_elo = normalize(white_elo_arr)\n",
    "\n",
    "#print(white_elo)\n",
    "white_elo = [torch.tensor(i, dtype = torch.float32) for i in white_elo]\n",
    "\n",
    "\n",
    "\n",
    "black_elo = np.array(df['BlackELO'])\n",
    "black_elo = [torch.tensor(i, dtype = torch.float32) for i in black_elo]\n",
    "\n",
    "\n",
    "# splitting into train and test\n",
    "lengths_train, lengths_test,eval_train, eval_test, black_train, black_test, white_train, white_test  = train_test_split(lengths, evals, black_elo, white_elo, test_size=0.2,random_state=0, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping the elo together with the evaluations\n",
    "train_data_zip = list(zip(eval_train, white_train))\n",
    "test_data_zip = list(zip(eval_test, white_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_elo = torch.stack(black_elo)\n",
    "white_elo = torch.stack(white_elo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, no_layers):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.no_layers = no_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, no_layers, batch_first = True, bias = True)\n",
    "        self.fc = nn.Linear(hidden_size,1, bias = False)\n",
    "        self.final = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out, _ = self.rnn(x)\n",
    "\n",
    "        # shape batches, seq_length, hidden_size\n",
    "        output ,lengths = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first = True)\n",
    "\n",
    "        out = [output[e, i-1,:].unsqueeze(0) for e, i in enumerate(lengths)]\n",
    "        out = torch.cat(out, dim = 0)\n",
    "        #print(out.shape)\n",
    "        #print(\"Linear weights\", self.fc.weight)\n",
    "\n",
    "\n",
    "        out = self.fc(out)\n",
    "        out = self.final(out)\n",
    "        #print(out.shape)\n",
    "        out = out[:,0]\n",
    "        return out\n",
    "\n",
    "\n",
    "    #def init_hidden(self):\n",
    "    #    return nn.init.kaiming_uniform_(torch.empty(1, self.hidden_size))\n",
    "\n",
    "# need to figure out exactly how the dimensions changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    '''\n",
    "    Yields a batch from a list of Items\n",
    "    Args:\n",
    "    test : Set True when using with test data loader. Defaults to False\n",
    "    percentile : Trim sequences by this percentile\n",
    "    '''\n",
    "\n",
    "    # remove that eventually. I'm going to need to make my dataset a tuple with evals and elo\n",
    "    #def __init__(self):\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        data = [item[0] for item in batch]\n",
    "        target = [item[1] for item in batch]\n",
    "        lens = [i.shape[0] for i in data]\n",
    "\n",
    "        #print(lens)\n",
    "        data = torch.nn.utils.rnn.pad_sequence(data, batch_first=True,padding_value = 0)\n",
    "        #data = data.unsqueeze(2)\n",
    "        #print(\"PADDED\",data)\n",
    "        evals_packed = torch.nn.utils.rnn.pack_padded_sequence(data,batch_first = True, lengths=lens,enforce_sorted=False)\n",
    "\n",
    "        target = torch.tensor(target,dtype=torch.float32)\n",
    "        return [evals_packed,target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 1\n",
    "no_layers = 2\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (defining my model)\n",
    "model = MyRNN(input_size, hidden_size, no_layers)\n",
    "collate = MyCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print('name: ', name)\n",
    "#     print(type(param))\n",
    "#     print('param.shape: ', param.shape)\n",
    "#     print('param.requires_grad: ', param.requires_grad)\n",
    "#     print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_train = [torch.tensor(i, dtype = torch.float32) for i in eval_train]\n",
    "#white_train = [torch.tensor(i, dtype = torch.float32) for i in white_train]\n",
    "\n",
    "#eval_train = torch.stack(eval_train)\n",
    "#white_train = torch.stack(white_train)\n",
    "\n",
    "#train_data = list(zip(evals_packed, white_train))\n",
    "\n",
    "\n",
    "#eval_test = [torch.tensor(i, dtype=torch.float32) for i in eval_test]\n",
    "#white_test = [torch.tensor(i, dtype=torch.float32) for i in white_test]\n",
    "\n",
    "#eval_test = torch.stack(eval_test)\n",
    "#white_test = torch.stack(white_test)\n",
    "\n",
    "\n",
    "# not sure why I'm seeing a warning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MyRNN(\n",
      "  (rnn): RNN(2, 1, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=1, out_features=1, bias=False)\n",
      "  (final): Tanh()\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_data_zip, batch_size=batch_size, shuffle=True ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK I've figured out the issue, I also need the sequence length for the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 step 71 - Learning Rate : 0.2- Avg Loss: 1.051589 - Change in loss: 1.0515886507928371\n"
     ]
    }
   ],
   "source": [
    "avg_losses = []\n",
    "epochs = []\n",
    "avg_loss = 1\n",
    "\n",
    "for epoch in range(1):\n",
    "\n",
    "    if (epoch+1) % 10 ==0:\n",
    "        learning_rate /= 2\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    i = 0\n",
    "    losses = []\n",
    "    for evals, elo in data_loader:\n",
    "        evals = evals.to(device)\n",
    "\n",
    "        elo = elo.to(device)\n",
    "        i +=1\n",
    "        outputs = model(evals)\n",
    "        #print(outputs)\n",
    "        #print(outputs.shape, elo.shape)\n",
    "        loss = criterion(outputs,elo)\n",
    "\n",
    "        # optimizing\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    change = stats.mean(losses)/avg_loss\n",
    "    avg_loss = stats.mean(losses)\n",
    "    avg_losses.append(avg_loss)\n",
    "    epochs.append(epoch)\n",
    "    print(f'Epoch {epoch+1} step {i+1} - Learning Rate : {learning_rate}- Avg Loss: {avg_loss:3f} - Change in loss: {change}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why are 4/5 always zero???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x185314eae00>"
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(epochs, avg_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "MyRNN(\n  (rnn): RNN(2, 1, num_layers=2, batch_first=True)\n  (fc): Linear(in_features=1, out_features=1, bias=False)\n  (final): Tanh()\n)"
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = torch.utils.data.DataLoader(test_data_zip, batch_size=1, shuffle=False ,collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss : 1.111939091359216\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "outputs = []\n",
    "elos = []\n",
    "for evals, elo in test_data_loader:\n",
    "    #print(\"evals\",evals.shape)\n",
    "    evals = evals.to(device)\n",
    "    elo = elo.to(device)\n",
    "    output = model(evals)\n",
    "    outputs.append(output.item())\n",
    "    elos.append(elo.item())\n",
    "    loss = criterion(output,elo)\n",
    "    #print(f'Model prediction : {output} \\n ELO : {elo} \\n MSE : {loss}')\n",
    "    losses.append(loss.item())\n",
    "print(f'Average loss : {stats.mean(losses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.1158], grad_fn=<SelectBackward0>)"
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.collections.PathCollection at 0x185314b84c0>"
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(elos,outputs, alpha = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the neural net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "outputs": [],
   "source": [
    "model =model.eval()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "outputs": [],
   "source": [
    "# note - to use any of these, I'm not sure that I can use the packed sequence. I would have to change the way the NN works, a little bit\n",
    "tb = SummaryWriter()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02719307690858841\n",
      "-0.1323186159133911\n"
     ]
    }
   ],
   "source": [
    "print(max(outputs))\n",
    "print(min(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "outputs": [],
   "source": [
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "#traced_script_module = torch.jit.trace(model, example)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object Module.named_parameters at 0x00000185314C3680>"
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "outputs": [
    {
     "data": {
      "text/plain": "{'rnn.weight_ih_l0': Parameter containing:\n tensor([[-0.4058, -0.9276]], requires_grad=True),\n 'rnn.weight_hh_l0': Parameter containing:\n tensor([[-0.1015]], requires_grad=True),\n 'rnn.bias_ih_l0': Parameter containing:\n tensor([-0.1055], requires_grad=True),\n 'rnn.bias_hh_l0': Parameter containing:\n tensor([-0.0654], requires_grad=True),\n 'rnn.weight_ih_l1': Parameter containing:\n tensor([[0.3629]], requires_grad=True),\n 'rnn.weight_hh_l1': Parameter containing:\n tensor([[0.3433]], requires_grad=True),\n 'rnn.bias_ih_l1': Parameter containing:\n tensor([0.2474], requires_grad=True),\n 'rnn.bias_hh_l1': Parameter containing:\n tensor([-0.2463], requires_grad=True),\n 'fc.weight': Parameter containing:\n tensor([[0.2766]], requires_grad=True)}"
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "outputs": [],
   "source": [
    "dot = make_dot(output.mean(), params=dict(model.named_parameters()), show_attrs=True, show_saved=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [],
   "source": [
    "#ot = graphviz.Digraph('dot', graph_attr={'nslimit': '0','nslimit1': '2'},node_attr={'shape': 'plaintext'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "outputs": [],
   "source": [
    "# dot = graphviz.Digraph('dot',format=\"png\",\n",
    "#               engine='neato', # Layout engine.\n",
    "#               graph_attr=dict(splines='true',\n",
    "#                               sep='5',\n",
    "#                               overlap='scale'),\n",
    "#               node_attr=dict(shape='circle',\n",
    "#                              margin='0',\n",
    "#                              fontsize='10',\n",
    "#                              width='0.2',\n",
    "#                              height='0.2',\n",
    "#                              fixedsize='true'),\n",
    "#               edge_attr=dict(arrowsize='0.4'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [
    {
     "data": {
      "text/plain": "'rnn_torchviz2.pdf'"
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot.render(\"rnn_torchviz2\", format=\"pdf\", engine= 'neato')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [243]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# note - doesn't support packed stuff\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43monnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m               \u001B[49m\u001B[38;5;66;43;03m# model being run\u001B[39;49;00m\n\u001B[0;32m      3\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m                         \u001B[49m\u001B[38;5;66;43;03m# model input (or a tuple for multiple inputs)\u001B[39;49;00m\n\u001B[0;32m      4\u001B[0m \u001B[43m                  \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msuper_resolution.onnx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m   \u001B[49m\u001B[38;5;66;43;03m# where to save the model (can be a file or file-like object)\u001B[39;49;00m\n\u001B[0;32m      5\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# store the trained parameter weights inside the model file\u001B[39;49;00m\n\u001B[0;32m      6\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m          \u001B[49m\u001B[38;5;66;43;03m# the ONNX version to export the model to\u001B[39;49;00m\n\u001B[0;32m      7\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# whether to execute constant folding for optimization\u001B[39;49;00m\n\u001B[0;32m      8\u001B[0m \u001B[43m                  \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m   \u001B[49m\u001B[38;5;66;43;03m# the model's input names\u001B[39;49;00m\n\u001B[0;32m      9\u001B[0m \u001B[43m                  \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moutput\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# the model's output names\u001B[39;49;00m\n\u001B[0;32m     10\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbatch_size\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# variable length axes\u001B[39;49;00m\n\u001B[0;32m     11\u001B[0m \u001B[43m                                \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43moutput\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbatch_size\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\onnx\\utils.py:504\u001B[0m, in \u001B[0;36mexport\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001B[0m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;129m@_beartype\u001B[39m\u001B[38;5;241m.\u001B[39mbeartype\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexport\u001B[39m(\n\u001B[0;32m    188\u001B[0m     model: Union[torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule, torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mScriptModule, torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mScriptFunction],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    204\u001B[0m     export_modules_as_functions: Union[\u001B[38;5;28mbool\u001B[39m, Collection[Type[torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    205\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001B[39;00m\n\u001B[0;32m    207\u001B[0m \n\u001B[0;32m    208\u001B[0m \u001B[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    501\u001B[0m \u001B[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001B[39;00m\n\u001B[0;32m    502\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 504\u001B[0m     \u001B[43m_export\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    512\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    513\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    514\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    515\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    516\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\onnx\\utils.py:1529\u001B[0m, in \u001B[0;36m_export\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001B[0m\n\u001B[0;32m   1526\u001B[0m     dynamic_axes \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m   1527\u001B[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001B[1;32m-> 1529\u001B[0m graph, params_dict, torch_out \u001B[38;5;241m=\u001B[39m \u001B[43m_model_to_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1530\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1531\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1532\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1533\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1534\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1535\u001B[0m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1536\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_do_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1537\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfixed_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfixed_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1538\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1539\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1540\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1542\u001B[0m \u001B[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001B[39;00m\n\u001B[0;32m   1543\u001B[0m defer_weight_export \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1544\u001B[0m     export_type \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _exporter_states\u001B[38;5;241m.\u001B[39mExportTypes\u001B[38;5;241m.\u001B[39mPROTOBUF_FILE\n\u001B[0;32m   1545\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\onnx\\utils.py:1111\u001B[0m, in \u001B[0;36m_model_to_graph\u001B[1;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001B[0m\n\u001B[0;32m   1108\u001B[0m     args \u001B[38;5;241m=\u001B[39m (args,)\n\u001B[0;32m   1110\u001B[0m model \u001B[38;5;241m=\u001B[39m _pre_trace_quant_model(model, args)\n\u001B[1;32m-> 1111\u001B[0m graph, params, torch_out, module \u001B[38;5;241m=\u001B[39m \u001B[43m_create_jit_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1112\u001B[0m params_dict \u001B[38;5;241m=\u001B[39m _get_named_param_dict(graph, params)\n\u001B[0;32m   1114\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\onnx\\utils.py:987\u001B[0m, in \u001B[0;36m_create_jit_graph\u001B[1;34m(model, args)\u001B[0m\n\u001B[0;32m    982\u001B[0m     graph \u001B[38;5;241m=\u001B[39m _C\u001B[38;5;241m.\u001B[39m_propagate_and_assign_input_shapes(\n\u001B[0;32m    983\u001B[0m         graph, flattened_args, param_count_list, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    984\u001B[0m     )\n\u001B[0;32m    985\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m graph, params, torch_out, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 987\u001B[0m graph, torch_out \u001B[38;5;241m=\u001B[39m \u001B[43m_trace_and_get_graph_from_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    988\u001B[0m _C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_lint(graph)\n\u001B[0;32m    989\u001B[0m state_dict \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39m_unique_state_dict(model)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\onnx\\utils.py:891\u001B[0m, in \u001B[0;36m_trace_and_get_graph_from_model\u001B[1;34m(model, args)\u001B[0m\n\u001B[0;32m    889\u001B[0m prev_autocast_cache_enabled \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mis_autocast_cache_enabled()\n\u001B[0;32m    890\u001B[0m torch\u001B[38;5;241m.\u001B[39mset_autocast_cache_enabled(\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m--> 891\u001B[0m trace_graph, torch_out, inputs_states \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_trace_graph\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    894\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    895\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_force_outplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    896\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_return_inputs_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    897\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    898\u001B[0m torch\u001B[38;5;241m.\u001B[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001B[0;32m    900\u001B[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\jit\\_trace.py:1184\u001B[0m, in \u001B[0;36m_get_trace_graph\u001B[1;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001B[0m\n\u001B[0;32m   1182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(args, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m   1183\u001B[0m     args \u001B[38;5;241m=\u001B[39m (args,)\n\u001B[1;32m-> 1184\u001B[0m outs \u001B[38;5;241m=\u001B[39m ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outs\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\jit\\_trace.py:95\u001B[0m, in \u001B[0;36mONNXTracedModule.forward\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m---> 95\u001B[0m     in_vars, in_desc \u001B[38;5;241m=\u001B[39m \u001B[43m_flatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;66;03m# NOTE: use full state, because we need it for BatchNorm export\u001B[39;00m\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;66;03m# This differs from the compiler path, which doesn't support it at the moment.\u001B[39;00m\n\u001B[0;32m     98\u001B[0m     module_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(_unique_state_dict(\u001B[38;5;28mself\u001B[39m, keep_vars\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39mvalues())\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# note - doesn't support packed stuff\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb.add_graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, no_layers):\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.no_layers = no_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, no_layers, batch_first = True, bias = False)\n",
    "        self.fc = nn.Linear(hidden_size,1, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # initial hidden state\n",
    "        h0 = torch.rand(self.no_layers,x.size(0),self.hidden_size)\n",
    "\n",
    "        out, _ = self.rnn(x,h0)\n",
    "        #print(out) #return out\n",
    "        out = out[:,-1,:]\n",
    "        #print(out)\n",
    "        out = self.fc(out)\n",
    "        #print(out)\n",
    "        m = nn.Sigmoid()\n",
    "        out = m(out)\n",
    "        return out\n",
    "        # print(\"out: \",out)\n",
    "        # print('RNN WEIGHTS: ',self.rnn.weight_ih_l0  )\n",
    "        # print(self.fc.weight)\n",
    "        #\n",
    "        # #print(\"Count these...\",out)\n",
    "        # m = nn.Sigmoid()\n",
    "        # out = m(out)\n",
    "        # if x.size(0) == 1:\n",
    "        #     return out[0]\n",
    "        # else:\n",
    "        #     return torch.squeeze(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyRNN(input_size, hidden_size, no_layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
